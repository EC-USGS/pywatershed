{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66cf7f2b-ca2e-40b0-81e9-6cf8bfd0e2eb",
   "metadata": {},
   "source": [
    "# PRMSChannel FlowGraph with a STARFIT Reservoir: Big Sandy Reservoir\n",
    "\n",
    "This notebook demonstrates the capabilities of the `FlowGraph` class and its associated classes\n",
    "`FlowNode` and `FlowNodeMaker` in a real-world example. This example starts from an existing graph of \n",
    "flow, embedded in `PRMSChannel` and its parameters, and adds in a single new node to represent a reservoir\n",
    "within the `PRMSChannel` simulation. \n",
    "\n",
    "The `FlowGraph` is the class which is able to take different flow methods and combine them in \n",
    "user-specified ways. In this case we combine nodes of class `PRMSChannelFlowNode` (a re-expression\n",
    "of `PRMSChannel` as a `FlowNode` to work with `FlowGraph`) with one node of class `StarfitFlowNode`. \n",
    "\n",
    "Please see these links to the documentation for more details on each:\n",
    "[`FlowGraph`](https://pywatershed.readthedocs.io/en/latest/api/generated/pywatershed.FlowGraph.html), \n",
    "[`StarfitFlowNode`](https://pywatershed.readthedocs.io/en/latest/api/generated/pywatershed.StarfitFlowNode.html), and \n",
    "[`PRMSChannelFlowNode`](https://pywatershed.readthedocs.io/en/latest/api/generated/pywatershed.PRMSChannelFlowNode.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cab067-be80-4743-b09a-410c215abfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "from pprint import pprint\n",
    "\n",
    "import jupyter_black\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "\n",
    "import hvplot.xarray  # noqa, after xr\n",
    "import hvplot.pandas  # noqa, after pandas\n",
    "\n",
    "import pyPRMS\n",
    "import pywatershed as pws\n",
    "from pywatershed.plot import DomainPlot\n",
    "from pywatershed.constants import zero\n",
    "\n",
    "ndays_run = 365 * 2\n",
    "plot_height = 600\n",
    "plot_width = 1000\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9478cf-9126-4bbe-993e-a2cb6d04001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.utils.addtl_domain_files.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac724e3-5d9c-4e8e-9334-2f7f0be643b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_output_dir = pl.Path(\"./06_flow_graph_starfit\")\n",
    "if not nb_output_dir.exists():\n",
    "    nb_output_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d5271-3976-430b-a754-b7a72e336704",
   "metadata": {},
   "source": [
    "## The Big Sandy Dike and the Flaming Gorge Domain\n",
    "Let's get to know something about this domain and reservoir. We'll load the full Global Reservoir and Dam (GRanD) data set and pull out the row for Big Sandy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60dd131-c4d9-49cf-a376-556db6c23935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below in this cell is how one would get parameters for reservoirs in the ISTARF-CONUS database.\n",
    "# We use pre-canned parameters and do not do this here because the GRanD file\n",
    "# must be downloaded manually from\n",
    "# https://ln.sync.com/dl/bd47eb6b0/anhxaikr-62pmrgtq-k44xf84f-pyz4atkm/view/default/447819520013\n",
    "# unpacked and placed in the location below, which can not be automated\n",
    "# for testing this notebook.\n",
    "# param_src_dir = nb_output_dir / \"param_sources\"\n",
    "# param_src_dir.mkdir(exist_ok=True)\n",
    "# grand_file = param_src_dir / \"GRanD_Version_1_3/GRanD_reservoirs_v1_3.dbf\"\n",
    "# sf_params = pws.parameters.StarfitParameters.from_istarf_conus_grand(\n",
    "#     grand_file=grand_file,\n",
    "#     files_directory=param_src_dir,\n",
    "#     grand_ids=[419],  # the id for Big Sandy\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec574d-111e-4637-8389-9bb777a7f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_root = pws.constants.__pywatershed_root__\n",
    "big_sandy_param_file = pkg_root / \"data/big_sandy_starfit_parameters.nc\"\n",
    "sf_params = pws.Parameters.from_netcdf(big_sandy_param_file, use_xr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7f96d-bb4d-4631-a77b-f20ae11912c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look in pandas format\n",
    "sf_params.to_xr_ds().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f46834-677f-4f3f-9c76-a53034e8b65e",
   "metadata": {},
   "source": [
    "The reservoir capacity is 67.1 million cubic meters (MCM). Let's find it on a map... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3878e-0308-413f-a1d1-36a8f64956d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_lat = sf_params.parameters[\"LAT_DD\"]\n",
    "start_lon = sf_params.parameters[\"LONG_DD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10004a14-785a-43f4-abc6-5102156d219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dir = pkg_root / \"data/pywatershed_addtl_domains/fgr_2yr\"\n",
    "domain_gis_dir = pkg_root / \"data/pywatershed_gis/fgr_2yr\"\n",
    "\n",
    "control_file = domain_dir / \"nhm.control\"\n",
    "\n",
    "shp_file_hru = domain_gis_dir / \"model_nhru.shp\"\n",
    "shp_file_seg = domain_gis_dir / \"model_nsegment.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19533c6d-35b4-4017-9d03-a8992ca3f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_plot = DomainPlot(\n",
    "    hru_shp_file=shp_file_hru,\n",
    "    segment_shp_file=shp_file_seg,\n",
    "    hru_parameters=domain_dir / \"parameters_dis_hru.nc\",\n",
    "    hru_parameter_names=[\n",
    "        \"nhm_id\",\n",
    "        \"hru_lat\",\n",
    "        \"hru_lon\",\n",
    "        \"hru_area\",\n",
    "    ],\n",
    "    segment_parameters=domain_dir / \"parameters_dis_seg.nc\",\n",
    "    segment_parameter_names=[\n",
    "        \"nhm_seg\",\n",
    "        \"tosegment\",\n",
    "        \"seg_length\",\n",
    "        \"seg_slope\",\n",
    "        \"seg_cum_area\",\n",
    "    ],\n",
    "    start_lat=start_lat,\n",
    "    start_lon=start_lon,\n",
    "    start_zoom=13,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170d616-a760-455d-a88f-19ffc2205121",
   "metadata": {},
   "source": [
    "From the above, by mousing over the segments we can see the reservoir would be inserted above nhm_seg 44426 and below nhm_segs 44434 and 44435. \n",
    "\n",
    "For more context, zooming out shows the full Flaming Gorge Domain on the Green River. The openstreetmap layers shows that Big Sandy Dike is located near Farson, WY. In the EsriSatellite layer, we observe this is a very dry, high plains region with farming downstream of the Big Sandy and Eden reservoirs around Farson. We can also see that the reservoir is fed by snowpack and seasonal runoff from the high Wind River Range to the Northeast. The photo of Arrowhead Lake below (taken by the author in August 2023) looks southeast at Temple Mountain, across the furthest upstream HRU of the Big Sandy Dike. \n",
    "![Arrowhead Lake, August 2023](static/arrowhead_lake.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ccde5-0a85-491e-911c-4045aa68aa12",
   "metadata": {},
   "source": [
    "## NHM Run on Flaming Gorge Domain: NO Big Sandy\n",
    "The NHM does not represent any reservoirs. From the above plot, we'll assume the outflows of Big Sandy would be at segment 44426. Let's see how the NHM represents flow at this location, without any reservoir representation. We can run pywatershed using the \"legacy instantation\" as described in Notebook 02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64dd07-cc07-4175-9f49-dffd532f7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pws.Control.load_prms(control_file, warn_unused_options=False)\n",
    "control.edit_n_time_steps(ndays_run)\n",
    "\n",
    "parameter_file = domain_dir / control.options[\"parameter_file\"]\n",
    "params = pws.parameters.PrmsParameters.load(parameter_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288d4c9-a1f0-423f-b580-e43230651d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll output the to-channel fluxes for use later when running FlowGraph as a post-process.\n",
    "run_dir = nb_output_dir / \"fgr_nhm\"\n",
    "\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": domain_dir,\n",
    "    \"budget_type\": \"error\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "    \"netcdf_output_var_names\": [\n",
    "        \"seg_outflow\",\n",
    "        \"sroff_vol\",\n",
    "        \"ssres_flow_vol\",\n",
    "        \"gwres_flow_vol\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "nhm_processes = [\n",
    "    pws.PRMSSolarGeometry,\n",
    "    pws.PRMSAtmosphere,\n",
    "    pws.PRMSCanopy,\n",
    "    pws.PRMSSnow,\n",
    "    pws.PRMSRunoff,\n",
    "    pws.PRMSSoilzone,\n",
    "    pws.PRMSGroundwater,\n",
    "    pws.PRMSChannel,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96b9ba-1253-4a41-abfb-3444de3b37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not run_dir.exists():\n",
    "    # must delete the run dir to re-run\n",
    "    run_dir.mkdir()\n",
    "    nhm = pws.Model(\n",
    "        nhm_processes,\n",
    "        control=control,\n",
    "        parameters=params,\n",
    "    )\n",
    "    nhm.run(finalize=True)\n",
    "    nhm.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfb7bc-5ebe-4fb8-a4f6-91a8370f3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow = xr.open_dataarray(run_dir / \"seg_outflow.nc\").sel(nhm_seg=44426)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec64846-76af-4934-a304-f40f33b0cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow.hvplot(width=plot_width, height=plot_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5905f87-c4d7-47fe-ba52-cb51be05a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow_obs = (\n",
    "    xr.open_dataarray(run_dir / \"seg_outflow.nc\")\n",
    "    .sel(nhm_seg=44438)\n",
    "    .rename(\"modeled\")\n",
    "    .to_dataframe()[\"modeled\"]\n",
    ")\n",
    "obs_all = pyPRMS.DataFile(domain_dir / \"sf_data\").data_by_variable(\"runoff\")\n",
    "wh_poi_obs = np.where(params.parameters[\"poi_gage_segment\"] == 184)\n",
    "gage_id = params.parameters[\"poi_gage_id\"][wh_poi_obs][0]\n",
    "obs = obs_all[f\"runoff_{gage_id}\"]\n",
    "obs.rename(\"gage \" + obs.name, inplace=True)\n",
    "\n",
    "outflow_obs.hvplot() * obs[0 : (365 * 2)].hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07caf286-e581-4cbd-83ad-e0b960e56911",
   "metadata": {},
   "source": [
    "## FlowGraph in Model: NHM with a STARFIT representation of Big Sandy\n",
    "\n",
    "Because FlowGraph is not part of PRMS, we cant run FlowGraph with PRMS/NHM using the legacy instantiation (eg. notebook 02). We have to use a multi-process model, and set it up \"the pywatershed way\" (as described in notebook 01). The next three cells build the multi-process model which flows into the FlowGraph. We then use a helper function to insert the STARFIT resevoir into the `FlowNode` representation of the PRMS/NHM Muskingum-Mann channel routing and we append this `FlowGraph` to our multi-process model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328c9fd-8afd-4bd5-8326-ed093d3610d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_file_channel = domain_dir / \"parameters_PRMSChannel.nc\"\n",
    "params_channel = pws.parameters.PrmsParameters.from_netcdf(params_file_channel)\n",
    "\n",
    "dis_file = domain_dir / \"parameters_dis_hru.nc\"\n",
    "dis_hru = pws.Parameters.from_netcdf(dis_file, encoding=False)\n",
    "\n",
    "dis_both_file = domain_dir / \"parameters_dis_both.nc\"\n",
    "dis_both = pws.Parameters.from_netcdf(dis_both_file, encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d62fe-2742-48df-ae87-21ba419dd1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pws.Control.load_prms(control_file, warn_unused_options=False)\n",
    "control.edit_n_time_steps(ndays_run)\n",
    "run_dir = nb_output_dir / \"fgr_starfit\"\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": domain_dir,\n",
    "    \"budget_type\": \"error\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "    \"netcdf_output_var_names\": [\n",
    "        \"node_outflows\",\n",
    "        \"node_upstream_inflows\",\n",
    "        \"node_storages\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb9546-c026-4aa8-b9ea-9d37d7ece0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhm_processes = [\n",
    "    pws.PRMSSolarGeometry,\n",
    "    pws.PRMSAtmosphere,\n",
    "    pws.PRMSCanopy,\n",
    "    pws.PRMSSnow,\n",
    "    pws.PRMSRunoff,\n",
    "    pws.PRMSSoilzone,\n",
    "    pws.PRMSGroundwater,  # stop here, we'll add PRMSChannel as part of FlowGraph later\n",
    "]\n",
    "\n",
    "model_dict = {\n",
    "    \"control\": control,\n",
    "    \"dis_both\": dis_hru,\n",
    "    \"dis_hru\": dis_both,\n",
    "    \"model_order\": [],\n",
    "}\n",
    "\n",
    "# As in notebook 01\n",
    "for proc in nhm_processes:\n",
    "    proc_name = proc.__name__\n",
    "    proc_rename = \"prms_\" + proc_name[4:].lower()\n",
    "    model_dict[\"model_order\"] += [proc_rename]\n",
    "    model_dict[proc_rename] = {}\n",
    "    proc_dict = model_dict[proc_rename]\n",
    "    proc_dict[\"class\"] = proc\n",
    "    proc_param_file = domain_dir / f\"parameters_{proc_name}.nc\"\n",
    "    proc_dict[\"parameters\"] = pws.Parameters.from_netcdf(proc_param_file)\n",
    "    if proc_rename == \"prms_channel\":\n",
    "        proc_dict[\"dis\"] = \"dis_both\"\n",
    "    else:\n",
    "        proc_dict[\"dis\"] = \"dis_hru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b170049-ec6b-4a6d-b183-98effa92d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what did that give us?\n",
    "pprint(model_dict, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229c613-56fe-49c0-b211-f0f047eddc57",
   "metadata": {},
   "source": [
    "Now we have a model dictionary describing all the processes which flow into the `PRMSChannel` (Musking-Mann). We have a very nice helper function, `prms_channel_flow_graph_to_model_dict`, we can use to add a `FlowGraph` to this model. The function takes the existing `model_dict`, the `PRMSChannel` data, plus additional user-supplied information, to construct a `FlowGraph` new nodes inserted in to the `PRMSChannel`. In this case we'll add a single new node to the `PMRSChannel`, this will be a `StarfitFlowNode` inserted at the location above nhm segment 44426 (and below 44434 and 44435) to represent the Big Sandy dike. This `FlowGraph` instance is finaly added to the `model_dict` with the name \"prms_channel_flow_graph\". \n",
    "\n",
    "We'll see that the `prms_channel_flow_graph_to_model_dict` helper function will also add an `InflowExchange` instance to the `model_dict` named \"inflow_exchange\". This `InflowExchange` which will manage getting the fluxes from the other process into to the FlowGraph. Zero lateral flows are supplied to the StarfitNode for Big Sandy in this case (though we could do otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db25a89a-7a37-405e-ad09-1bfe682cabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pws.prms_channel_flow_graph_to_model_dict(\n",
    "    model_dict=model_dict,\n",
    "    prms_channel_dis=dis_both,\n",
    "    prms_channel_dis_name=\"dis_both\",\n",
    "    prms_channel_params=params_channel,\n",
    "    new_nodes_maker_dict={\n",
    "        \"starfit\": pws.hydrology.starfit.StarfitFlowNodeMaker(\n",
    "            None,\n",
    "            sf_params,\n",
    "            budget_type=\"error\",\n",
    "            compute_daily=True,\n",
    "        )\n",
    "    },\n",
    "    new_nodes_maker_names=[\"starfit\"],\n",
    "    new_nodes_maker_indices=[0],\n",
    "    new_nodes_maker_ids=[999],\n",
    "    new_nodes_flow_to_nhm_seg=[44426],\n",
    "    graph_budget_type=\"warn\",  # move to error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2e182-0475-42cf-be92-2d36154cad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"inflow_exchange\" and \"prms_channel_flow_graph\" have been added to the model\n",
    "pprint(model_dict, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece847a1-c229-4813-9dee-eb3be5d1cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not run_dir.exists():\n",
    "    run_dir.mkdir()\n",
    "    model = pws.Model(model_dict)\n",
    "    model.run()\n",
    "    model.finalize()\n",
    "\n",
    "    model.processes[\"prms_channel_flow_graph\"].budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc97a64-807c-4fa3-a3a3-d4d404fd25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_44426 = np.where(params.parameters[\"nhm_seg\"] == 44426)[0]\n",
    "outflow_nodes = xr.open_dataarray(run_dir / \"node_outflows.nc\")[:, wh_44426]\n",
    "outflow_nodes = outflow_nodes.drop_vars(set(outflow_nodes.coords) - {\"time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af336c0-e846-4fd9-a2d0-6728c4c42d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([outflow, outflow_nodes]).rename(\n",
    "    {\"seg_outflow\": \"NHM\", \"node_outflows\": \"STARFIT\"}\n",
    ").hvplot(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    ylabel=\"streamflow (cfs)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e2590-a439-4ee5-90d2-625fa06f9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_nodes = xr.open_dataarray(run_dir / \"node_storages.nc\")[:, -1]\n",
    "storage_nodes = storage_nodes.drop_vars(set(storage_nodes.coords) - {\"time\"})\n",
    "storage_nodes.hvplot(width=plot_width, height=plot_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31416c-f0ed-4adc-81bc-8e968f927b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([outflow, outflow_nodes, storage_nodes]).rename(\n",
    "    {\n",
    "        \"seg_outflow\": \"NHM\",\n",
    "        \"node_outflows\": \"Big Sandy Outflow\",\n",
    "        \"node_storages\": \"Big Sandy Storage\",\n",
    "    }\n",
    ").hvplot(\n",
    "    width=int(plot_width / 1.25),\n",
    "    height=int(plot_height / 1.3 / 1.2),\n",
    "    ylabel=\"streamflow (cfs)\\nstorage (million cubic feet)\",\n",
    ").opts(\n",
    "    legend_position=\"top_left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14432433-2385-4c21-992a-a05fc9524f11",
   "metadata": {},
   "source": [
    "## FlowGraph as a post-process: Drive FlowGraph with STARFIT representation of Big Sandy and Pass-Through using NHM output files\n",
    "Above we ran the equivalent of the full NHM but with a `StarfitNode` inserted at Big Sandy. Pywatershed is flexible and no two process representations are two-way coupled in the NHM configuration. This means that the `FlowGraph` in the model run above could be run as a post-process on the rest of the model chain.\n",
    "\n",
    "In fact, we can use the output of the first model run above, without any reservoir representation, to drive just the `FlowGraph` in the previous run. We call running `FlowGraph` in this way a \"post-process\". If one were running the no-reservoir model and investigating hypotheses of what FlowGraph designs give better flow representations, this is the method you'd want to follow instead of running all the model processes above `FlowGraph` every time.\n",
    "\n",
    "For this post-process case we have a different helper function, `prms_channel_flow_graph_postprocess`, to which we supply most of the same information about the `FlowGraph`. However, we tell it about where it can find inputs from file rather than about an existing `model_dict` (as in the previous model above).\n",
    "\n",
    "For extra fun and illustration, we'll not only add the `StarfitNode` for Big Sandy, we'll demonstrate that we can add additional nodes to the `FlowGraph` by putting a random `PassThroughFlowNode` elsewhere on the domain. This node has no effect on the flows by design, but adding it here shows how additional nodes can easily be added to a `FlowGraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aaced3-9191-4acb-9043-24bcb2623e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pws.Control.load_prms(control_file, warn_unused_options=False)\n",
    "control.edit_n_time_steps(ndays_run)\n",
    "run_dir = nb_output_dir / \"fgr_starfit_post\"\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": domain_dir,\n",
    "    \"budget_type\": \"error\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "    \"netcdf_output_var_names\": [\n",
    "        \"node_outflows\",\n",
    "        \"node_upstream_inflows\",\n",
    "        \"node_storages\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "params_file_channel = domain_dir / \"parameters_PRMSChannel.nc\"\n",
    "params_channel = pws.parameters.PrmsParameters.from_netcdf(params_file_channel)\n",
    "\n",
    "if \"dis_hru\" in locals().keys():\n",
    "    del dis_hru\n",
    "\n",
    "dis_both_file = domain_dir / \"parameters_dis_both.nc\"\n",
    "dis_both = pws.Parameters.from_netcdf(dis_both_file, encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c52566-9032-49ed-8012-382c9f5cd5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_ds = sf_params.to_xr_ds().copy()\n",
    "cap_mult = 1.5\n",
    "sfp_ds[\"GRanD_CAP_MCM\"] *= cap_mult\n",
    "sf_params_new = pws.Parameters.from_ds(sfp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c8589-f15d-4174-b2c8-ffd0b7214b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = nb_output_dir / \"fgr_nhm\"  # use the output of the NHM run\n",
    "\n",
    "flow_graph = pws.prms_channel_flow_graph_postprocess(\n",
    "    control=control,\n",
    "    input_dir=input_dir,\n",
    "    prms_channel_dis=dis_both,\n",
    "    prms_channel_params=params_channel,\n",
    "    new_nodes_maker_dict={\n",
    "        \"starfit\": pws.hydrology.starfit.StarfitFlowNodeMaker(\n",
    "            None,\n",
    "            sf_params_new,\n",
    "            compute_daily=False,\n",
    "            budget_type=\"error\",\n",
    "        ),\n",
    "        \"pass_through\": pws.hydrology.pass_through_flow_node.PassThroughFlowNodeMaker(),\n",
    "    },\n",
    "    new_nodes_maker_names=[\"starfit\", \"pass_through\"],\n",
    "    new_nodes_maker_indices=[0, 0],  # relative to the indvidual NodeMakers\n",
    "    new_nodes_maker_ids=[999, 9999],  # relative to the indvidual NodeMakers\n",
    "    new_nodes_flow_to_nhm_seg=[\n",
    "        44426,\n",
    "        44435,\n",
    "    ],  # the second is a pass through above the first\n",
    "    addtl_output_vars=[\"spill\", \"release\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5619ab-f399-4303-a6f5-4e656971424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not run_dir.exists():\n",
    "    run_dir.mkdir()\n",
    "    flow_graph.initialize_netcdf()\n",
    "    for istep in tqdm(range(control.n_times)):\n",
    "        control.advance()\n",
    "        flow_graph.advance()\n",
    "        flow_graph.calculate(1.0)\n",
    "        flow_graph.output()\n",
    "\n",
    "    flow_graph.finalize()\n",
    "    flow_graph.budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c3100-3db4-489e-8d29-b755b0807cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wh_44426 = np.where(params.parameters[\"nhm_seg\"] == 44426)[0]\n",
    "outflow_nodes_post = xr.open_dataarray(run_dir / \"node_outflows.nc\")\n",
    "wh_big_sandy = (outflow_nodes_post.node_maker_id == 999) & (\n",
    "    outflow_nodes_post.node_maker_name == \"starfit\"\n",
    ")\n",
    "outflow_nodes_post = outflow_nodes_post[:, wh_big_sandy].rename(\n",
    "    \"node_outflows_post\"\n",
    ")\n",
    "outflow_nodes_post = outflow_nodes_post.drop_vars(\n",
    "    set(outflow_nodes_post.coords) - {\"time\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9e92e-1e96-478c-a381-d5b2fd0d45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge(\n",
    "    [\n",
    "        outflow,\n",
    "        outflow_nodes,\n",
    "        outflow_nodes_post,\n",
    "    ]\n",
    ").rename(\n",
    "    {\n",
    "        \"seg_outflow\": \"NHM\",\n",
    "        \"node_outflows\": \"STARFIT\",\n",
    "        \"node_outflows_post\": f\"STARFIT CAP*{cap_mult}\",\n",
    "    }\n",
    ").hvplot(width=plot_width, height=plot_height, ylabel=\"streamflow (cfs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c762a-77e4-44d1-a75b-560ea9f6ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_nodes_post = xr.open_dataarray(run_dir / \"node_storages.nc\")\n",
    "wh_big_sandy = (storage_nodes_post.node_maker_id == 999) & (\n",
    "    storage_nodes_post.node_maker_name == \"starfit\"\n",
    ")\n",
    "storage_nodes_post = storage_nodes_post[:, wh_big_sandy].rename(\n",
    "    \"node_storages_post\"\n",
    ")\n",
    "storage_nodes_post = storage_nodes_post.drop_vars(\n",
    "    set(storage_nodes_post.coords) - {\"time\"}\n",
    ")\n",
    "xr.merge(\n",
    "    [\n",
    "        storage_nodes,\n",
    "        storage_nodes_post,\n",
    "    ]\n",
    ").hvplot(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    ylabel=\"storage (million cubic feet)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38758377-ee47-4c77-8bb7-721e7581b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge(\n",
    "    [\n",
    "        outflow,\n",
    "        outflow_nodes,\n",
    "        storage_nodes,\n",
    "        outflow_nodes_post,\n",
    "        storage_nodes_post,\n",
    "    ]\n",
    ").rename(\n",
    "    {\n",
    "        \"seg_outflow\": \"NHM\",\n",
    "        \"node_outflows\": \"Big Sandy Outflow\",\n",
    "        \"node_storages\": \"Big Sandy Storage\",\n",
    "        \"node_outflows_post\": f\"Big Sandy Outflow CAP*{cap_mult}\",\n",
    "        \"node_storages_post\": f\"Big Sandy Storage CAP*{cap_mult}\",\n",
    "    }\n",
    ").hvplot(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    ylabel=\"streamflow (cfs)\\nstorage (million cubic feet)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c74f780-a421-441b-a7ee-f2ff24b759ee",
   "metadata": {},
   "source": [
    "While the `FlowGraph` itself only looks at lateral inflows, upstream inflows, and total outflows at each node, there may be other variables of interest on a node for the user. Looking at the properties or attributes of an individual `FlowNode` reveals what other variables are available for each node of that type. Above, the argument `addtl_output_vars=[\"spill\", \"release\"]` was passed in the call to `pws.prms_channel_flow_graph_postprocess`. This requests that these variables are output to NetCDF files on nodes where they are available. Nodes where these variables are not available will contain missing (NaN) values. In the case of `StarfitFlowNode`s, the total outflow has two components, the spill and the release. From the node outflow variable, we can not see the individual contribution of these terms. So we request these variables are output and we see that in the second summer (June 13-16, 1980) there is indeed a spill event on Big Sandy which contributes to the total outflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9cf577-85e6-49ce-8a66-8862beb5aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spill = xr.open_dataarray(run_dir / \"spill.nc\")[:, wh_big_sandy]\n",
    "release = xr.open_dataarray(run_dir / \"release.nc\")[:, wh_big_sandy]\n",
    "drop_vars = set(spill.coords) - {\"time\"}\n",
    "spill = spill.drop_vars(drop_vars)\n",
    "release = release.drop_vars(drop_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f20212-0e10-4b75-9533-62002324d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge(\n",
    "    [\n",
    "        outflow_nodes_post,\n",
    "        spill,\n",
    "        release,\n",
    "    ]\n",
    ").rename(\n",
    "    {\n",
    "        \"node_outflows_post\": f\"Big Sandy Outflow CAP*{cap_mult}\",\n",
    "        \"spill\": f\"Big Sandy Spill CAP*{cap_mult}\",\n",
    "        \"release\": f\"Big Sandy Release  CAP*{cap_mult}\",\n",
    "    }\n",
    ").hvplot(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    ylabel=\"streamflow (cfs)\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
