{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0b7d2c-cfb0-40fe-aefc-d3f7d8647b94",
   "metadata": {},
   "source": [
    "# Performance Eval: fortran, numba, numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d965f-6c4a-42d5-8e0f-62b35c12da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "import pywatershed\n",
    "\n",
    "repo_root = pywatershed.constants.__pywatershed_root__.parent\n",
    "data_dir = pl.Path(\"../../../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557061f6-603f-4f9a-a8af-6d7c10faf897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate control, params, inputs, model and run it to completion with budget choice\n",
    "def proc_model_performance(process, domain, calc_method, budget_type: str = 'warn'):\n",
    "    \n",
    "    domain_dir = repo_root / f\"test_data/{domain}\"\n",
    "\n",
    "    input_dir = domain_dir / \"output\"\n",
    "    \n",
    "    params = pywatershed.PrmsParameters.load(domain_dir / \"myparam.param\")\n",
    "    control = pywatershed.Control.load(domain_dir / \"control.test\", params=params)\n",
    "\n",
    "    input_variables = {}\n",
    "    for key in process.get_inputs():\n",
    "      nc_path = input_dir / f\"{key}.nc\"\n",
    "      input_variables[key] = nc_path\n",
    "\n",
    "    proc_model = process(\n",
    "      control,\n",
    "      **input_variables,\n",
    "      budget_type=budget_type,\n",
    "      calc_method=calc_method,\n",
    "    )\n",
    "\n",
    "    for istep in range(control.n_times):\n",
    "      control.advance()\n",
    "      proc_model.advance()\n",
    "      proc_model.calculate(float(istep))\n",
    "\n",
    "    proc_model.finalize()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc61fbd3-905a-4b2b-9fac-aae6503aac59",
   "metadata": {},
   "source": [
    "# Generate performance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a10338f-f370-436a-b399-b6355412ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['conus_2yr', 'drb_2yr', 'ucb_2yr', 'hru_1']\n",
    "calc_methods = ['numba', 'fortran', 'numpy']\n",
    "processes = [pywatershed.PRMSCanopy, pywatershed.PRMSChannel, pywatershed.PRMSGroundwater,]\n",
    "results = []\n",
    "ii = 0\n",
    "for pp in processes:\n",
    "    for dd in domains:\n",
    "        for cc in calc_methods:\n",
    "            \n",
    "            if (dd == 'conus_2yr') and (pp == pywatershed.PRMSChannel):\n",
    "                if (cc == 'fortran') or (cc == 'numpy'):\n",
    "                    # some trouble with the networkx ordering? self._segment_order is wrong length going to f90\n",
    "                    continue\n",
    "\n",
    "            print(ii)\n",
    "            ii += 1\n",
    "            if (pp.__name__ != \"PRMSGroundwater\") and (cc == 'jax'):\n",
    "                continue  # only implemented for PRMSGroundwater so far\n",
    "            print('\\n', pp.__name__, dd, cc)\n",
    "            result = %timeit -o -n4 -r1 proc_model_performance(pp, dd, cc)\n",
    "            results += [{(pp.__name__, dd, cc): result}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9692091-c00f-44a4-b6e2-d4fbf40ef0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_post = {}\n",
    "for rr in results:\n",
    "    kk = list(rr.keys())[0]\n",
    "    vv = list(rr.values())[0]\n",
    "    results_post[kk] = {'mean': vv.average, 'stdev': vv.stdev, 'N': vv.repeat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d98ad-4eb3-4261-a101-04154ac0d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499332e-63f5-4832-870e-dd2b5c960ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventually save to disk using pickle\n",
    "# this code worked well in pynhm_nhm_performance, do similar change up the path\n",
    "# import pickle\n",
    "# for path, result in results.items():\n",
    "#     path = pl.Path(path)\n",
    "#     pkl_path = path.parent.parent /  (f\"results/{path.parent.name}_{path.name}_compile_performance.pkl\")\n",
    "#     print(pkl_path)\n",
    "#\n",
    "#     with open(pkl_path, \"wb\") as output_file:\n",
    "#         pickle.dump(result, output_file)\n",
    "# results2 = {}\n",
    "# files = (data_dir / 'pynhm/performance_runs/results/').glob('*.pkl')\n",
    "# for ff in files: \n",
    "#     print(ff)\n",
    "#     with open(ff, \"rb\") as input_file:\n",
    "#         results2[ff.name[0:-4]] = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279608fb-4cc7-42a0-bebf-1d6b4d506756",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_post_sav = results_post.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d150b18-79d7-4204-8224-6b372a240efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.plotting.backend = 'holoviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06152e3c-df48-4ecd-9f47-d8096245454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results_post).T\n",
    "results_df.index.set_names(names = [\"process\", \"domain\", \"calc\"], inplace=True)\n",
    "#results_df.sort_index(inplace=True) #this kills the show\n",
    "categories_order = ['hru_1', 'drb_2yr', 'ucb_2yr', 'conus_2yr']\n",
    "categories = pd.CategoricalIndex(results_df.index.levels[1].values,\n",
    "                                 categories=categories_order,\n",
    "                                 ordered=True)\n",
    "results_df.index.set_levels(categories, level='domain', inplace=True)\n",
    "results_df.sort_index(inplace=True)\n",
    "results_df\n",
    "# drop suspicious conus channel result\n",
    "results_df.drop(('PRMSChannel', 'conus_2yr'), axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3623516-d04d-4521-be0d-17077abcc280",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pp in [\"PRMSGroundwater\", 'PRMSCanopy', \"PRMSChannel\"]:\n",
    "    proc_df = results_df.loc[pp, slice(None), slice(None), slice(None)] \n",
    "    display(\n",
    "        proc_df.plot.bar().opts(\n",
    "            title=pp, \n",
    "            height=450, width=800,\n",
    "            ylabel='Mean Time (seconds)', \n",
    "            xlabel='',  # 'Domain: Calculation Method',\n",
    "            xrotation = 65,\n",
    "            fontscale=1.5,\n",
    "            #ylim=ylim,\n",
    "            show_grid=True,\n",
    "            logy=True, \n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0079c-951d-4d8e-986f-ccef6cf29741",
   "metadata": {},
   "outputs": [],
   "source": [
    "(proc_df.plot.bar().opts(title=pp) * \n",
    " proc_df.hvplot.errorbars(y='mean', yerr1='stdev'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29bcfac-77e3-4ada-93d2-e5ad7fd0ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df_ri = proc_df.reset_index()\n",
    "proc_df_ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0d724-0832-4e76-930a-f5b4a1883a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df_ri.plot.bar(y='mean') * proc_df_ri.hvplot.errorbars(x='index',y='mean', yerr1='stdev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce5afad-579f-4c13-abe2-bae99984dd6a",
   "metadata": {},
   "source": [
    "# Performance profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda6256-ae4a-4909-90bf-aeb6581e5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e6e42-2ad2-4c77-8722-1719228c2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%snakeviz\n",
    "proc_model_performance(pywatershed.PRMSChannel, 'ucb_2yr', 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0aae82-dc1d-4c6c-af06-d33713747c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%snakeviz\n",
    "proc_model_performance(pywatershed.PRMSChannel, 'ucb_2yr', 'fortran')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adfef3c-f33d-41d3-b49f-8953656f62f2",
   "metadata": {},
   "source": [
    "## Notes on profiles\n",
    "\n",
    "### PRMSGroundwater  \n",
    "The calculations take about 2-2.5% of runtime regardless of method ?and domain?\n",
    "The overall run times have a significant portion in reading input: storageUnit: advanceInput takes about 75% of runtime.  \n",
    "\n",
    "\n",
    "### PRMSCanopy\n",
    "hru_1: the calculations take about 1% of runtime\n",
    "ucb_2yr: numpy calculations take about 75% of run time, fortran is about 2%. \n",
    "\n",
    "### PRMSChannel\n",
    "hru_1: \n",
    "ucb_2_yr: numpy calculations take 95% of runtime. fortran calculations take 52% of runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b7e35d-2658-4d66-a4e2-6dccd8102f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
