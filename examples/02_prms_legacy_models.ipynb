{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f842ce-586b-490c-9e9e-97321918e5b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "# Multi-process models in pywatershed: PRMS-legacy instantiation\n",
    "\n",
    "Because pywatershed has its roots in the Precipitation-Runoff Modeling System (PRMS, Regan et al., 2015), pywatershed supports PRMS-model instantation from legacy PRMS input files. The traditional PRMS input files are the control file, the parameter file, and the climate-by-hru (CBH) files (typically daily precipitation and maximum and minimum temperatures). While the CBH files need to be pre-processed to NetCDF format, native PRMS control and parameter files are supported. \n",
    "\n",
    "Below we'll show how to preprocess the CBH files to NetCDF and how to instantiate a pywatershed `Model` using PRMS-native files. In this notebook we'll reproduce the basic results from the previous notebook (`01_multi-process_models.ipynb`) for the NHM full model and its submodel. As in the previous notebooks, run PRMS processes models on the Delaware River Basin (DRB) subdomain of the NHM for a 2 year period using `pywatershed`.\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275fe95-8e0b-45f9-837c-ad6f7d38ced7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# auto-format the code in this notebook\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e410d-c806-4467-8d56-e6add8c7f516",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "from platform import processor\n",
    "from pprint import pprint\n",
    "from shutil import rmtree\n",
    "from sys import platform\n",
    "import warnings\n",
    "\n",
    "import pydoc\n",
    "\n",
    "import hvplot.pandas  # noqa\n",
    "import numpy as np\n",
    "import pywatershed as pws\n",
    "from pywatershed.utils import gis_files\n",
    "import xarray as xr\n",
    "\n",
    "gis_files.download()  # this downloads GIS files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39abd69f-13a3-4f23-9678-a57c0b1f848d",
   "metadata": {},
   "source": [
    "The domain directory is where we have all the required inputs to run this model (among others) and `nb_output_dir` is where this notebook will write its output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4950eb10-25c0-403c-80ef-857cd003bc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dir = pws.constants.__pywatershed_root__ / \"data/drb_2yr\"\n",
    "nb_output_dir = pl.Path(\"./02_prms_legacy_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45c9899-3c4d-4cc9-b493-572d31a88426",
   "metadata": {},
   "source": [
    "## Preprocess CBH files to NetCDF format\n",
    "We need to preprocess CBH to NetCDF files, let's see how to do it! We'll create a directory to hold these files and then we'll process precipitiation (prcp), maximum temperature (tmax), and minimum temperature (tmin) files from CBH to NetCDF using a utility from pywatershed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1928ec2-577a-4c3a-b931-da574c079f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbh_nc_dir = nb_output_dir / \"drb_2yr_cbh_files\"\n",
    "if cbh_nc_dir.exists():\n",
    "    rmtree(cbh_nc_dir)\n",
    "cbh_nc_dir.mkdir(parents=True)\n",
    "\n",
    "cbh_files = [\n",
    "    domain_dir / \"prcp.cbh\",\n",
    "    domain_dir / \"tmax.cbh\",\n",
    "    domain_dir / \"tmin.cbh\",\n",
    "]\n",
    "\n",
    "params = pws.parameters.PrmsParameters.load(domain_dir / \"myparam.param\")\n",
    "\n",
    "for cbh_file in cbh_files:\n",
    "    out_file = cbh_nc_dir / cbh_file.with_suffix(\".nc\").name\n",
    "    pws.utils.cbh_file_to_netcdf(cbh_file, params, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fa3d3-60b6-4c0e-9b12-817ce4daeda1",
   "metadata": {},
   "source": [
    "## An NHM multi-process model: PRMS-legacy instantation\n",
    "\n",
    "The 8 conceptual `Process` classes that comprise the NHM in pywatershed are, in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529247fe-7f0b-4783-90a4-a4ddf55c1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhm_processes = [\n",
    "    pws.PRMSSolarGeometry,\n",
    "    pws.PRMSAtmosphere,\n",
    "    pws.PRMSCanopy,\n",
    "    pws.PRMSSnow,\n",
    "    pws.PRMSRunoff,\n",
    "    pws.PRMSSoilzone,\n",
    "    pws.PRMSGroundwater,\n",
    "    pws.PRMSChannel,\n",
    "]\n",
    "\n",
    "submodel_processes = [pws.PRMSSoilzone, pws.PRMSGroundwater, pws.PRMSChannel]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460bc54-bba5-4493-9d1f-e2fe6672b186",
   "metadata": {},
   "source": [
    "A multi-process model, comprised of the above `Process`es (see notebook `00_processes.ipynb`), is assembled by the `Model` class. We can take a quick look at the first 22 lines of help on `Model`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40a716-cc0c-4645-b03c-e4e4c4294697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is equivalent to help() but we get the multiline string and just look at part of it\n",
    "model_help = pydoc.render_doc(pws.Model, \"Help on %s\")\n",
    "# the first 22 lines of help(pws.Model)\n",
    "print(\"\\n\".join(model_help.splitlines()[0:22]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63cb1e9-d954-4541-83d2-0d2613cb7d8d",
   "metadata": {},
   "source": [
    "The `help()` mentions that there are 2 distinct ways of instantiating a `Model` class. In this notebook, we focus on the PRMS-legacy instantiation (see previous notebook for the pywatershed-centric way).\n",
    "\n",
    "With the PRMS-legacy approach, the first argument is a \"process list\", which is what we defined with the 8 NHM classes above. In addition, we must also supply the `control` and `parameters` arguments. The full `help()` describes PRMS-legacy instantation and provides examples. Please use it for reference and more details. Here we'll give an extended concrete example. \n",
    "\n",
    "We already loaded a `PrmsParameters` object from a PRMS-native file when we converted the CBH files. We'll just check that it is an instance/subclass of the `Parameters` class. Then we'll return the object (which invokes the `__repr__` method on the object, just giving information about it) to see what we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488f925-fac2-4911-b474-2cb3c9b012b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(isinstance(params, pws.Parameters))\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ac849-9093-4b34-af70-e5e56988f298",
   "metadata": {},
   "source": [
    "We now load the PRMS-native control file into a `Control` object, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc606f-4d69-439f-84cb-00b78ae13605",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    control = pws.Control.load_prms(domain_dir / \"nhm.control\")\n",
    "\n",
    "control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4f386-9c31-438f-89d7-76241ca9ab69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "When loading this PRMS-native parameter control file, we suppress warnings that indicating which PRMS options are not being used by pywatershed. For complete discussion of these see the help on `Control.load_prms()` in the documentation. The documentation covers what we also see in the above output, that the `netcdf_output_var_names` in `control.options` is the combination of `nhruOutVar_names` and `nsegmentOutVar_names` from the PRMS-native `nhm.control` file. The reqested output is different in this example than in the previous notebook, where all variables were output, for this reason. We'll keep all these variables for this model run and reduce the requested output later on in this notebook. However we'll need to add two pywatershed variables to this list to be able to run the sub-model below. \n",
    "\n",
    "Now we'll edit this control instance. First, we'll add the additional two output variables necessary to provide boundary conditions to the sub-model below. Next, we'll reduce the total simulation time to six months for the purposes of this demonstration (but feel free to increase this to the full 2 years available, if you like). Then, we'll specify several global options, including the location of the atmospheric forcing/input data, the budget type, and the calculation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153f49a-9848-48aa-a3ef-071713933b7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "control.options[\"netcdf_output_var_names\"] += [\"infil_hru\", \"sroff_vol\"]\n",
    "control.edit_end_time(np.datetime64(\"1979-07-01T00:00:00\"))\n",
    "run_dir = nb_output_dir / \"nhm\"\n",
    "if run_dir.exists():\n",
    "    rmtree(run_dir)\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": cbh_nc_dir,\n",
    "    \"budget_type\": \"warn\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46e9ca-e84b-40b3-bdc5-179fd6c85555",
   "metadata": {},
   "source": [
    "Now we can initialize the NHM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b2ad91-9e4a-4b25-9510-d9d927f0acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhm = pws.Model(\n",
    "    nhm_processes,\n",
    "    control=control,\n",
    "    parameters=params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c69fc4-34c3-48bf-948f-0df7c5769c78",
   "metadata": {},
   "source": [
    "Numba is a Python package for just-in-time compiling. It takes code written using the `numpy` package and accelerates it by compiling at run time. The processes listed above compiled their code on initialization of the model. The processes that benefit from jit compiling are challenging to vectorize and have a loop over space which is accelerated by the compiling. The remaining processes, not jit compiled, are all vectorized (in space and time): PRMSSolarGeometry, PRMSAtmosphere. In fact, these two compute for all time at the beginning of the simulation (which is why there is a pause before the time loop starts in the next cell.)\n",
    "\n",
    "Now we can run the model, requesting it finalize at the end, and we'll time the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33866b9-d490-4b80-b8ee-2f02eb86525b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nhm.run(finalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d528e-01f0-4cf0-855e-eea532672836",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Now that we've run our NHM model on the DRB, let's take a look at the simulated streamflow. Still in memory are the streamflow values from the final timestep, we'll plot those on the stream network overlaid on the watershed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a3a1d-4f98-4f86-a25b-c53e44783b61",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "proc_plot = pws.analysis.ProcessPlot(gis_files.gis_dir / \"drb_2yr\")\n",
    "proc_name = \"PRMSChannel\"\n",
    "var_name = \"seg_outflow\"\n",
    "proc = nhm.processes[proc_name]\n",
    "proc_plot.plot(var_name, proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83052466-f75f-41e0-9b6d-4982dbe2e338",
   "metadata": {},
   "source": [
    "Above we see the network on which streamflow is calculated, and the final simulated values of streamflow. \n",
    "\n",
    "Let us turn towards the model structure in more detail: how do atmospheric inputs/forcings result in the simulated streamflow above? We will produce the model graph which shows the flow of information from the input files through all the process representations, all the way down to the channel streamflow. First, we print a color legend for each represented process in the NHM. Each process is outlined by a box of this color and values/fluxes flowing from a process have the color of the originating process. Finally, a variable outlined in blue (above and on the sides) participates in the mass budget of its process. This diagram gives some very specific information of the model conceptualization, how the processes relate to each other, and the complexity of the indivdual processes. (Note that the underlying graphviz/dot program that generates the plot is not fully working on Mac ARM/M1, so plots here and below are less detailed if you are are using such a machine, the notebooks in the repo will be complete for your reference.) Each process's data is placed into one of three categories: inputs(blue), parameters(orange), and variables(green). All of this information is public for each process (indeed in static methods) so we can produce these plots programatically without needing to run the `Model`. As discussed in the previous notebook, the `Model` object contains all the information needed to generate the plot when it is initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95574d33-f8ff-42f4-ae9b-316dcc152a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = pws.analysis.utils.colorbrewer.nhm_process_colors(nhm)\n",
    "pws.analysis.utils.colorbrewer.jupyter_palette(palette)\n",
    "show_params = not (platform == \"darwin\" and processor() == \"arm\")\n",
    "try:\n",
    "    pws.analysis.ModelGraph(\n",
    "        nhm,\n",
    "        hide_variables=False,\n",
    "        process_colors=palette,\n",
    "        show_params=show_params,\n",
    "    ).SVG(verbose=True, dpi=48)\n",
    "except:\n",
    "    static_url = \"https://private-user-images.githubusercontent.com/12465248/259783743-7813cba0-343c-4bf1-9b15-6ed92930f288.svg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTg4MzcwMTQsIm5iZiI6MTcxODgzNjcxNCwicGF0aCI6Ii8xMjQ2NTI0OC8yNTk3ODM3NDMtNzgxM2NiYTAtMzQzYy00YmYxLTliMTUtNmVkOTI5MzBmMjg4LnN2Zz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjE5VDIyMzgzNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTEzNWMxMTQ2MjE2YjM0NjI1ZDA4ZGI0Nzg1YTEyMTlkYjYxYWVhYmJjNTdkMTVjYzY0NzRkYjFkODU0ZGMxMTUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.MtkzgxHiDRsavGls_UNtKC54R0hyuXAs45u4SbvFO-c\"\n",
    "    print(\n",
    "        f\"Dot fails on some machines. You can see the graph at this url: {static_url}\"\n",
    "    )\n",
    "    from IPython.display import Image\n",
    "\n",
    "    display(Image(url=static_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf8b0f-5197-4467-8e2d-3c98060f8e68",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## NHM Submodel for the Delaware River Basin \n",
    "Now suppose you wanted to change parameters or model process representation in the PRMSSoilzone to better predict streamflow. As the model is 1-way coupled, you can simply run a submodel starting with PRMSSoilzone and running through PRMSChannel. We simply change our process list to get this \"submodel\" of the full NHM model above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88353277-76a3-423e-a913-b9575d9ebf02",
   "metadata": {},
   "source": [
    "We can reuse the existing parameter object (since it is write protected). However, we have to re-load the the control because it tracked time through the previous simulation. We point the model to look for input from the output for the full model above. We'll also turn off output by commenting `netcdf_output_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0ce51-937f-4dbe-8443-1857ed1be52a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "control_sub = pws.Control.load_prms(\n",
    "    domain_dir / \"nhm.control\", warn_unused_options=False\n",
    ")\n",
    "\n",
    "run_dir_submodel = nb_output_dir / \"nhm_submodel\"\n",
    "if run_dir_submodel.exists():\n",
    "    rmtree(run_dir_submodel)\n",
    "\n",
    "control_sub.edit_end_time(np.datetime64(\"1979-07-01T00:00:00\"))\n",
    "control_sub.options = control_sub.options | {\n",
    "    \"input_dir\": run_dir,\n",
    "    \"budget_type\": \"warn\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir_submodel,\n",
    "}\n",
    "\n",
    "control_sub.options[\"netcdf_output_var_names\"] = (\n",
    "    pws.PRMSChannel.get_variables()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a649ad-6137-455a-bc0b-d64a1e47a98a",
   "metadata": {},
   "source": [
    "We'll instantiate the model and display its `ModelGraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0a561-8642-40a9-8638-36d380672cc8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "submodel = pws.Model(\n",
    "    submodel_processes,\n",
    "    control=control_sub,\n",
    "    parameters=params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7f4f3-12d4-4dda-a7c3-6e1a761b4a5a",
   "metadata": {},
   "source": [
    "Now we'll run the submodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35002e93-b777-472e-8899-36548c1ea923",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "submodel.run(finalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca6466-cc1d-46ac-9b49-deb7f66b9414",
   "metadata": {},
   "source": [
    "We can visualize the sub-model with its `ModelGraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a0e229-8297-42af-8b07-aa416073d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_params = not (platform == \"darwin\" and processor() == \"arm\")\n",
    "try:\n",
    "    pws.analysis.ModelGraph(\n",
    "        submodel,\n",
    "        hide_variables=False,\n",
    "        process_colors=palette,\n",
    "        show_params=show_params,\n",
    "    ).SVG(verbose=True, dpi=48)\n",
    "except:\n",
    "    static_url = \"https://private-user-images.githubusercontent.com/12465248/259783766-e0902e7f-ac69-488c-8719-858315d45e7c.svg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTg4MzcwMTQsIm5iZiI6MTcxODgzNjcxNCwicGF0aCI6Ii8xMjQ2NTI0OC8yNTk3ODM3NjYtZTA5MDJlN2YtYWM2OS00ODhjLTg3MTktODU4MzE1ZDQ1ZTdjLnN2Zz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MTklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjE5VDIyMzgzNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFiMmVhNDg3MTNmYmFjNWE0NWQ3NDM0NTcyMTE4NWI0ZmMxMzQwOGQ4MjJjNjY5Y2NlM2U1YTcwN2VjYjRiYWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.N9V5vcLla2MENY5CTma4gomxbBSh3YIfYX0X6zfbzRM\"\n",
    "    print(\n",
    "        f\"Dot fails on some machines. You can see the graph at this url: {static_url}\"\n",
    "    )\n",
    "    from IPython.display import Image\n",
    "\n",
    "    display(Image(url=static_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c6f78-ade4-42d3-84fb-ceb71a462856",
   "metadata": {},
   "source": [
    "Finally we can check that the output of the model and the submodel are identical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc7082-d4fe-4237-8bd8-613dc692beeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_output_both = set(control.options[\"netcdf_output_var_names\"]) & set(\n",
    "    control_sub.options[\"netcdf_output_var_names\"]\n",
    ")\n",
    "for var in vars_output_both:\n",
    "    print(var)\n",
    "    nhm_da = xr.open_dataarray(run_dir / f\"{var}.nc\")\n",
    "    sub_da = xr.open_dataarray(run_dir_submodel / f\"{var}.nc\")\n",
    "    xr.testing.assert_equal(nhm_da, sub_da)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
