{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c56634-c85e-4e55-9500-96dfe5e2a3f0",
   "metadata": {},
   "source": [
    "# Model Loop Customization of Output\n",
    "Until a more sophisticated \"model obvserver\" functionality is developed, it's easy enough to customize\n",
    "output in the `model.run()` loop. One can subset in space (or time) and write to disk at desired \n",
    "times. Here, we'll grab a specific locations of both segments and HRUs at each time into an xarray \n",
    "Dataset which we'll then write out to disk at the end. If the we `model.initialize_netcdf(run_dir)`\n",
    "then we can compare our selected output against the full output. But turning off default output\n",
    "results in significant speedups, at least for a 2 year Delaware River Basin run and the subset of\n",
    "data specified, the timings are as follows: \n",
    "\n",
    "| calc_method | model.initialize_netcdf | time (m:ss) |\n",
    "| ------------|-------------------------|-------------|\n",
    "| numpy       | True                    | 0:31.6      |\n",
    "| numpy       | False                   | 0:29.6      |\n",
    "| numba       | True                    | 0:17.4      |\n",
    "| numba       | False                   | 0:10.7      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc9766-0473-4b1c-aa6e-1bb00355cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import math\n",
    "import pathlib as pl\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pywatershed as pws\n",
    "from tqdm import tqdm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c26385-07a5-488a-8add-78fc893d6100",
   "metadata": {},
   "source": [
    "Set up a full NHM model on the DRB domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbdd6ba-0ad4-45e1-9f59-e7d45914b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_components = [\n",
    "    pws.PRMSSolarGeometry,\n",
    "    pws.PRMSAtmosphere,\n",
    "    pws.PRMSCanopy,\n",
    "    pws.PRMSSnow,\n",
    "    pws.PRMSRunoff,\n",
    "    pws.PRMSSoilzone,\n",
    "    pws.PRMSGroundwater,\n",
    "    pws.PRMSChannel,\n",
    "]\n",
    "\n",
    "domain_name = 'drb_2yr'\n",
    "domain_dir = pl.Path(f'../test_data/{domain_name}')\n",
    "run_dir = pl.Path('.') / 'model_loop_custom_output'\n",
    "\n",
    "if run_dir.exists():\n",
    "    shutil.rmtree(run_dir)\n",
    "\n",
    "run_dir.mkdir()\n",
    "print(f'\\nRunning domain \"{domain_name}\" in {run_dir.resolve()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fde56c-7127-4daa-af3e-82dd4b130e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_initialize_netcdf = False\n",
    "calc_method = 'numba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c5a79-4169-4f56-bb3e-7304af4bc288",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = list(product([True, False], ['numpy', 'numba']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abeff3a-138e-4cf9-94be-29a01096e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_output_netcdf, calc_method in cases:\n",
    "\n",
    "    start_time = time.time()\n",
    "    custom_output_file = run_dir / \"model_custom_output.nc\"\n",
    "    \n",
    "    param_file = domain_dir / \"myparam.param\"\n",
    "    params = pws.parameters.PrmsParameters.load(param_file)\n",
    "    control = pws.Control.load_prms(domain_dir / \"nhm.control\", warn_unused_options=False)\n",
    "    \n",
    "    #Sets control options for both cases\n",
    "    control.options = control.options | {\n",
    "        \"input_dir\": domain_dir,\n",
    "        \"budget_type\": None,\n",
    "        \"verbosity\": 0,\n",
    "        \"calc_method\": calc_method,\n",
    "    }\n",
    "    \n",
    "    if model_output_netcdf:\n",
    "        control.options = control.options | {\n",
    "            \"netcdf_output_var_names\": [\n",
    "                \"hru_actet\",\n",
    "                #\"potet\",\n",
    "                \"tmaxf\",\n",
    "                \"sroff_vol\",\n",
    "                \"ssres_flow_vol\",\n",
    "                \"gwres_flow_vol\",\n",
    "                \"seg_outflow\",\n",
    "                \"hru_streamflow_out\",\n",
    "                \"recharge\",\n",
    "                \"snowcov_area\", \n",
    "                \"soil_rechr\",\n",
    "                #\"hru_actet\",\n",
    "                \"net_rain\",\n",
    "                \"net_snow\",\n",
    "                #\"net_ppt\",\n",
    "                #\"sroff\",\n",
    "                #\"ssres_flow\",\n",
    "                \"gwres_flow\",\n",
    "                #\"seg_outflow\",\n",
    "                #\"hru_streamflow_out\",\n",
    "                #\"recharge\",\n",
    "                #\"gwres_sink\",\n",
    "                \"snowmelt\",\n",
    "            ],\n",
    "            \"netcdf_output_dir\": run_dir,\n",
    "        }\n",
    "    else:\n",
    "        control.options = control.options | {\n",
    "            \"netcdf_output_var_names\": None,\n",
    "            \"netcdf_output_dir\": None,\n",
    "        }\n",
    "    \n",
    "    model = pws.Model(\n",
    "        [\n",
    "            pws.PRMSSolarGeometry,\n",
    "            pws.PRMSAtmosphere,\n",
    "            pws.PRMSCanopy,\n",
    "            pws.PRMSSnow,\n",
    "            pws.PRMSRunoff,\n",
    "            pws.PRMSSoilzone,\n",
    "            pws.PRMSGroundwater,\n",
    "            pws.PRMSChannel,\n",
    "        ],\n",
    "        control=control,\n",
    "        parameters=params,\n",
    "    )\n",
    "    \n",
    "    # Custom model output at selected spatial locations for all times.\n",
    "    # Generally, i'd be careful with xarray performance, but just writing at the\n",
    "    # end should be fine.\n",
    "    # Could move to netcdf4 if performance is a concern.\n",
    "    \n",
    "    # /////////////////////////////////\n",
    "    # specfications: what we want this to look like to the user\n",
    "    var_list = [\n",
    "        \"hru_actet\",\n",
    "        #\"potet\",\n",
    "        \"tmaxf\",\n",
    "        \"seg_outflow\",\n",
    "        \"hru_actet\",\n",
    "        \"recharge\",\n",
    "        \"snowcov_area\",\n",
    "        \"soil_rechr\",\n",
    "        \"net_rain\",\n",
    "        \"net_snow\",\n",
    "        #\"net_ppt\",\n",
    "        #\"sroff\",# values in inches for area weighted averaging\n",
    "        #\"ssres_flow\",# values in inches for area weighted averaging\n",
    "        \"gwres_flow\",# values in inches for area weighted averaging\n",
    "        #\"gwres_sink\",\n",
    "        \"snowmelt\",\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # want seg_outflow just on poi_gages\n",
    "    # make it a tuple like the return of np.where\n",
    "    wh_gages = (params.parameters[\"poi_gage_segment\"] - 1,)# - 1 is related to the indexing in fortran; made a a tuple see above\n",
    "    spatial_subsets = {\n",
    "        \"poi_gages\": {\n",
    "            \"coord_name\": \"nhm_seg\",\n",
    "            \"indices\": wh_gages,\n",
    "            \"new_coord\": params.parameters[\"poi_gage_id\"],\n",
    "            \"variables\": [\"seg_outflow\", \"seg_gwflow\"],#can add any other var with same coord here, eg. seg_gwflow/\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # A novel, diagnostic variable\n",
    "    def sum_hru_flows(sroff_vol, ssres_flow_vol, gwres_flow_vol): #These vars used to calc, do not need to be in the var list\n",
    "        return sroff_vol + ssres_flow_vol + gwres_flow_vol\n",
    "    \n",
    "    \n",
    "    diagnostic_var_dict = {\n",
    "        \"hru_streamflow_out\": {\n",
    "            \"inputs\": [\"sroff_vol\", \"ssres_flow_vol\", \"gwres_flow_vol\"],\n",
    "            \"function\": sum_hru_flows,\n",
    "            \"like_var\": \"sroff_vol\",\n",
    "            \"metadata\": {\"desc\": \"Total volume to stream network from each HRU\", \"units\": \"cubic feet\"},\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    # TODO: specify subsets in time\n",
    "    # TODO: specify different output files\n",
    "    \n",
    "    # /////////////////////////////////\n",
    "    # code starts here\n",
    "    \n",
    "    out_subset_ds = xr.Dataset()\n",
    "    \n",
    "    needed_vars = var_list + [\n",
    "        var for key, val in diagnostic_var_dict.items() for var in val[\"inputs\"]\n",
    "    ]\n",
    "    needed_metadata = pws.meta.get_vars(needed_vars)\n",
    "    dims = set([dim for val in needed_metadata.values() for dim in val[\"dims\"]])\n",
    "    \n",
    "    subset_vars = [\n",
    "        var for key, val in spatial_subsets.items() for var in val[\"variables\"]\n",
    "    ]\n",
    "    \n",
    "    var_subset_key = {\n",
    "        var: subkey\n",
    "        for var in subset_vars\n",
    "        for subkey in spatial_subsets.keys()\n",
    "        if var in spatial_subsets[subkey][\"variables\"]\n",
    "    }\n",
    "    \n",
    "    diagnostic_vars = list(diagnostic_var_dict.keys())\n",
    "    \n",
    "    # solve the processes for each variable\n",
    "    var_proc = {\n",
    "        var: proc_key\n",
    "        for var in needed_vars\n",
    "        for proc_key, proc_val in model.processes.items()\n",
    "        if var in proc_val.get_variables()\n",
    "    }\n",
    "    \n",
    "    time_coord = np.arange(\n",
    "        control.start_time, control.end_time + control.time_step, dtype=\"datetime64[D]\"\n",
    "    )\n",
    "    n_time_steps = len(time_coord)\n",
    "    out_subset_ds[\"time\"] = xr.Variable([\"time\"], time_coord)\n",
    "    out_subset_ds = out_subset_ds.set_coords(\"time\")\n",
    "    \n",
    "    # annoying to have to hard-code this\n",
    "    dim_coord = {\"nhru\": \"nhm_id\", \"nsegment\": \"nhm_seg\"}\n",
    "    \n",
    "    ####################################################################################\n",
    "    # declare memory for the outputs\n",
    "    for var in var_list + diagnostic_vars:\n",
    "        # impostor approach\n",
    "        orig_diag_var = None\n",
    "        if var in diagnostic_vars:\n",
    "            orig_diag_var = var\n",
    "            var = diagnostic_var_dict[var][\"like_var\"]\n",
    "    \n",
    "        proc = model.processes[var_proc[var]]\n",
    "        dim_name = needed_metadata[var][\"dims\"][0]\n",
    "        dim_len = proc.params.dims[dim_name]\n",
    "        coord_name = dim_coord[dim_name]\n",
    "        coord_data = proc.params.coords[dim_coord[dim_name]]\n",
    "        type = needed_metadata[var][\"type\"]\n",
    "    \n",
    "        var_meta = {\n",
    "            kk: vv\n",
    "            for kk, vv in needed_metadata[var].items()\n",
    "            if kk in [\"desc\", \"units\"]\n",
    "        }\n",
    "    \n",
    "        if orig_diag_var is not None:\n",
    "            var = orig_diag_var\n",
    "            del var_meta[\"desc\"]\n",
    "            if \"metadata\" in diagnostic_var_dict[var]:\n",
    "                var_meta = diagnostic_var_dict[var][\"metadata\"]\n",
    "            if \"desc\" not in var_meta.keys():\n",
    "                var_meta[\"desc\"] = \"Custom output diagnostic variable\"\n",
    "    \n",
    "        if var in subset_vars:\n",
    "            subset_key = var_subset_key[var]\n",
    "            subset_info = spatial_subsets[subset_key]\n",
    "            dim_name = f\"n{subset_key}\"\n",
    "            coord_name = subset_key\n",
    "            dim_len = len(subset_info[\"indices\"][0])\n",
    "            coord_data = subset_info[\"new_coord\"]\n",
    "    \n",
    "        if coord_name not in list(out_subset_ds.variables):\n",
    "            out_subset_ds[coord_name] = xr.DataArray(coord_data, dims=[dim_name])\n",
    "            out_subset_ds = out_subset_ds.set_coords(coord_name)\n",
    "    \n",
    "        out_subset_ds[var] = xr.Variable(\n",
    "            [\"time\", dim_name],\n",
    "            np.full(\n",
    "                [n_time_steps, dim_len],\n",
    "                pws.constants.fill_values_dict[np.dtype(type)],\n",
    "                type,\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "        out_subset_ds[var].attrs = var_meta\n",
    "    \n",
    "    for istep in range(n_time_steps):\n",
    "        model.advance()\n",
    "        model.calculate()\n",
    "    \n",
    "        if model_output_netcdf:\n",
    "            model.output()\n",
    "    \n",
    "        for var in var_list:\n",
    "            proc = model.processes[var_proc[var]]\n",
    "            data = proc[var]\n",
    "            if isinstance(proc[var], pws.base.timeseries.TimeseriesArray):\n",
    "                data = data.current\n",
    "            if var not in subset_vars:\n",
    "                out_subset_ds[var][istep, :] = data\n",
    "            else:\n",
    "                indices = spatial_subsets[var_subset_key[var]][\"indices\"]\n",
    "                out_subset_ds[var][istep, :] = data[indices]\n",
    "    \n",
    "        for diag_key, diag_val in diagnostic_var_dict.items():\n",
    "            input_dict = {}\n",
    "            for ii in diag_val[\"inputs\"]:\n",
    "                proc = model.processes[var_proc[ii]]\n",
    "                input_dict[ii] = proc[ii]\n",
    "    \n",
    "            out_subset_ds[diag_key][istep, :] = diag_val[\"function\"](**input_dict)#this is where the diag_var is actually being calc'd/time step\n",
    "    \n",
    "    \n",
    "    out_subset_ds.to_netcdf(custom_output_file)\n",
    "    out_subset_ds.close()\n",
    "    \n",
    "    del proc\n",
    "    del input_dict\n",
    "    del model\n",
    "    del out_subset_ds\n",
    "\n",
    "    duration = time.time()-start_time\n",
    "    print(f\"({model_output_netcdf=}, {calc_method=}): {duration:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9edf3-ef79-4c47-ae49-ac261f7d1bbd",
   "metadata": {},
   "source": [
    "Check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ebd32-a5d9-48a7-b12e-ec31f955c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_subset_ds = xr.open_dataset(custom_output_file)\n",
    "\n",
    "for vv in var_list:\n",
    "    default_output_file = run_dir / f\"{vv}.nc\"\n",
    "    print(\"checking variable: \", vv)\n",
    "    answer = xr.load_dataarray(default_output_file)\n",
    "    \n",
    "    result = out_subset_ds[vv]\n",
    "\n",
    "    if vv in subset_vars:\n",
    "        indices = spatial_subsets[var_subset_key[vv]][\"indices\"]\n",
    "        answer = answer[:, indices[0]]\n",
    "\n",
    "    np.testing.assert_allclose(answer, result)\n",
    "    answer.close()\n",
    "\n",
    "for diag_key, diag_val in diagnostic_var_dict.items():\n",
    "    print(\"checking diagnostic variable: \", diag_key)\n",
    "    input_dict = {}\n",
    "    for ii in diag_val[\"inputs\"]:\n",
    "        default_output_file = run_dir / f\"{ii}.nc\"\n",
    "        input_dict[ii] = xr.load_dataarray(default_output_file)\n",
    "\n",
    "    answer = diag_val[\"function\"](**input_dict)\n",
    "    result = out_subset_ds[diag_key]\n",
    "\n",
    "    np.testing.assert_allclose(answer, result)\n",
    "    \n",
    "out_subset_ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dbc425-3a03-4d73-9061-cd15b71752cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0197a649-2509-4228-8d33-e242fd5654b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
