{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66cf7f2b-ca2e-40b0-81e9-6cf8bfd0e2eb",
   "metadata": {},
   "source": [
    "# PRMSChannel FlowGraph with a STARFIT Reservoir: Big Sandy Reservoir\n",
    "\n",
    "This notebook demonstrates the capabilities of the `FlowGraph` class and its associated classes\n",
    "`FlowNode` and `FlowNodeMaker` in a real-world example. This example starts from an existing\n",
    "flow graph which is in `PRMSChannel` and adds in a single new node to represent a reservoir\n",
    "within the `PRMSChannel` simulation. The `FlowGraph` is the class which is able to take different\n",
    "flow methods and combine them in user-specified ways. In this case we combine nodes of class\n",
    "`PRMSChannelFlowNode` with one node of class `StarfitFlowNode`. \n",
    "\n",
    "Please see these links to the documentation for more details on \n",
    "[`FlowGraph`](https://pywatershed.readthedocs.io/en/latest/api/generated/pywatershed.FlowGraph.html), \n",
    "[`StarfitFlowNode`](https://pywatershed.readthedocs.io/en/latest/api/generated/pywatershed.StarfitFlowNode.html), and \n",
    "[`PRMSChannelFlowNode`](https://pywatershed.readthedocs.io/en/latest/api/generated/pywatershed.PRMSChannelFlowNode.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cab067-be80-4743-b09a-410c215abfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "from pprint import pprint\n",
    "\n",
    "import jupyter_black\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "\n",
    "import hvplot.xarray  # noqa, after xr\n",
    "import hvplot.pandas  # noqa, after pandas\n",
    "\n",
    "import pyPRMS\n",
    "import pywatershed as pws\n",
    "from pywatershed.plot import DomainPlot\n",
    "from pywatershed.constants import zero\n",
    "\n",
    "ndays_run = 365 * 2\n",
    "plot_height = 600\n",
    "plot_width = 1000\n",
    "\n",
    "jupyter_black.load()\n",
    "\n",
    "# to remove:\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9478cf-9126-4bbe-993e-a2cb6d04001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pws.utils.addtl_domain_files.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac724e3-5d9c-4e8e-9334-2f7f0be643b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_output_dir = pl.Path(\"./06_flow_graph_starfit\")\n",
    "if not nb_output_dir.exists():\n",
    "    nb_output_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d5271-3976-430b-a754-b7a72e336704",
   "metadata": {},
   "source": [
    "## The Big Sandy Dike and the Flaming Gorge Domain\n",
    "Let's get to know something about this domain and reservoir. We'll load the full Global Reservoir and Dam (GRanD) data set and pull out the row for Big Sandy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec574d-111e-4637-8389-9bb777a7f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkg_root = pws.constants.__pywatershed_root__\n",
    "big_sandy_param_file = pkg_root / \"data/big_sandy_starfit_parameters.nc\"\n",
    "sf_params = pws.Parameters.from_netcdf(big_sandy_param_file, use_xr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7f96d-bb4d-4631-a77b-f20ae11912c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look in pandas format\n",
    "sf_params.to_xr_ds().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f46834-677f-4f3f-9c76-a53034e8b65e",
   "metadata": {},
   "source": [
    "The reservoir capacity is 67.1 million cubic meters (MCM). Let's find it on a map... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3878e-0308-413f-a1d1-36a8f64956d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_lat = sf_params.parameters[\"LAT_DD\"]\n",
    "start_lon = sf_params.parameters[\"LONG_DD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10004a14-785a-43f4-abc6-5102156d219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dir = pkg_root / \"data/pywatershed_addtl_domains/fgr_2yr\"\n",
    "domain_gis_dir = pkg_root / \"data/pywatershed_gis/fgr_2yr\"\n",
    "\n",
    "control_file = domain_dir / \"nhm.control\"\n",
    "\n",
    "shp_file_hru = domain_gis_dir / \"model_nhru.shp\"\n",
    "shp_file_seg = domain_gis_dir / \"model_nsegment.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19533c6d-35b4-4017-9d03-a8992ca3f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add GRanD shp file? or add to the object afterwards? option to get polygons\n",
    "# for sf_params above? but how to show connectivity?\n",
    "DomainPlot(\n",
    "    hru_shp_file=shp_file_hru,\n",
    "    segment_shp_file=shp_file_seg,\n",
    "    hru_parameters=domain_dir / \"parameters_dis_hru.nc\",\n",
    "    hru_parameter_names=[\n",
    "        \"nhm_id\",\n",
    "        \"hru_lat\",\n",
    "        \"hru_lon\",\n",
    "        \"hru_area\",\n",
    "    ],\n",
    "    segment_parameters=domain_dir / \"parameters_dis_seg.nc\",\n",
    "    segment_parameter_names=[\n",
    "        \"nhm_seg\",\n",
    "        \"tosegment\",\n",
    "        \"seg_length\",\n",
    "        \"seg_slope\",\n",
    "        \"seg_cum_area\",\n",
    "    ],\n",
    "    start_lat=start_lat,\n",
    "    start_lon=start_lon,\n",
    "    start_zoom=13,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1170d616-a760-455d-a88f-19ffc2205121",
   "metadata": {},
   "source": [
    "From the above, by mousing over the segments we can see the reservoir should be inserted above nhm_seg 44426 and below nhm_segs 44434 and 44435. \n",
    "\n",
    "For more context, zooming out shows the full Flaming Gorge Domain on the Green River. The openstreetmap layers shows that Big Sandy Dike is located near Farson, WY. In the EsriSatellite layer, we observe this is a very dry, high plains region with farming downstream of the Big Sandy and Eden reservoirs around Farson. We can also see that the reservoir is fed by snowpack and seasonal runoff from the high Wind River Range to the Northeast. The photo of Arrowhead Lake below (taken by the author in August 2023) looks southeast at Temple Mountain, across the furthest upstream HRU of the Big Sandy Dike. \n",
    "![Arrowhead Lake, August 2023](static/arrowhead_lake.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ccde5-0a85-491e-911c-4045aa68aa12",
   "metadata": {},
   "source": [
    "## NHM Run on Flaming Gorge Domain: NO Big Sandy\n",
    "The NHM does not represent any reservoirs. From above, we'll assume the outflows of Big Sandy are on segment 44426. We'll see how the NHM represents flow at Big Sandy.\n",
    "We can run pywatershed using the \"legacy instantation\" as described in Notebook 02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64dd07-cc07-4175-9f49-dffd532f7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pws.Control.load_prms(control_file, warn_unused_options=False)\n",
    "control.edit_n_time_steps(ndays_run)\n",
    "parameter_file = domain_dir / control.options[\"parameter_file\"]\n",
    "params = pws.parameters.PrmsParameters.load(parameter_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba984f-3402-416d-8800-0bee97158219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain_dir = pl.Path(\"/Users/jmccreight/usgs/data/pynhm/fgr_2yr\")\n",
    "# # run just once to convert CBH/day forcing files to pywatershed, NetCDF format\n",
    "# cbh_nc_dir = domain_dir\n",
    "# cbh_files = [\n",
    "#     domain_dir / \"prcp_2yr.cbh\",\n",
    "#     domain_dir / \"tmax_2yr.cbh\",\n",
    "#     domain_dir / \"tmin_2yr.cbh\",\n",
    "# ]\n",
    "\n",
    "# params = pws.parameters.PrmsParameters.load(domain_dir / \"myparam.param\")\n",
    "\n",
    "# for cbh_file in cbh_files:\n",
    "#     out_file = cbh_nc_dir / cbh_file.with_suffix(\".nc\").name\n",
    "#     pws.utils.cbh_file_to_netcdf(cbh_file, params, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288d4c9-a1f0-423f-b580-e43230651d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll output the to-channel fluxes for use later when running FlowGraph as a post-process.\n",
    "run_dir = nb_output_dir / \"fgr_nhm\"\n",
    "\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": domain_dir,\n",
    "    \"budget_type\": \"error\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "    \"netcdf_output_var_names\": [\n",
    "        \"seg_outflow\",\n",
    "        \"sroff_vol\",\n",
    "        \"ssres_flow_vol\",\n",
    "        \"gwres_flow_vol\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "nhm_processes = [\n",
    "    pws.PRMSSolarGeometry,\n",
    "    pws.PRMSAtmosphere,\n",
    "    pws.PRMSCanopy,\n",
    "    pws.PRMSSnow,\n",
    "    pws.PRMSRunoff,\n",
    "    pws.PRMSSoilzone,\n",
    "    pws.PRMSGroundwater,\n",
    "    pws.PRMSChannel,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96b9ba-1253-4a41-abfb-3444de3b37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not run_dir.exists():\n",
    "    # must delete the run dir to re-run\n",
    "    run_dir.mkdir()\n",
    "    nhm = pws.Model(\n",
    "        nhm_processes,\n",
    "        control=control,\n",
    "        parameters=params,\n",
    "    )\n",
    "    nhm.run(finalize=True)\n",
    "    nhm.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfb7bc-5ebe-4fb8-a4f6-91a8370f3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow = xr.open_dataarray(run_dir / \"seg_outflow.nc\").sel(nhm_seg=44426)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec64846-76af-4934-a304-f40f33b0cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow.hvplot(width=plot_width, height=plot_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54058459-fed5-4cc3-bed2-8a3edfb22a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow_obs = (\n",
    "    xr.open_dataarray(run_dir / \"seg_outflow.nc\")\n",
    "    .sel(nhm_seg=44438)\n",
    "    .rename(\"modeled\")\n",
    "    .to_dataframe()[\"modeled\"]\n",
    ")\n",
    "obs_all = pyPRMS.DataFile(domain_dir / \"sf_data\").data_by_variable(\"runoff\")\n",
    "wh_poi_obs = np.where(params.parameters[\"poi_gage_segment\"] == 184)\n",
    "gage_id = params.parameters[\"poi_gage_id\"][wh_poi_obs][0]\n",
    "obs = obs_all[f\"runoff_{gage_id}\"]\n",
    "obs.rename(\"gage \" + obs.name, inplace=True)\n",
    "\n",
    "outflow_obs.hvplot() * obs[0 : (365 * 2)].hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07caf286-e581-4cbd-83ad-e0b960e56911",
   "metadata": {},
   "source": [
    "## FlowGraph in Model: NHM with a STARFIT representation of Big Sandy\n",
    "\n",
    "Because FlowGraph is not part of PRMS, we cant run FlowGraph with PRMS/NHM using the legacy instantiation (eg. notebook 02). We have to use a multi-process model, the pywatershed way (e.g. notebook 01). The next three cells build the multi-process model above the FlowGraph. We then use a helper function to insert the STARFIT resevoir into the PRMS/NHM Muskingum-Mann channel routing and append it to our multi-process model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328c9fd-8afd-4bd5-8326-ed093d3610d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_file_channel = domain_dir / \"parameters_PRMSChannel.nc\"\n",
    "params_channel = pws.parameters.PrmsParameters.from_netcdf(params_file_channel)\n",
    "\n",
    "dis_file = domain_dir / \"parameters_dis_hru.nc\"\n",
    "dis_hru = pws.Parameters.from_netcdf(dis_file, encoding=False)\n",
    "\n",
    "dis_both_file = domain_dir / \"parameters_dis_both.nc\"\n",
    "dis_both = pws.Parameters.from_netcdf(dis_both_file, encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d62fe-2742-48df-ae87-21ba419dd1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pws.Control.load_prms(control_file, warn_unused_options=False)\n",
    "control.edit_n_time_steps(ndays_run)\n",
    "run_dir = nb_output_dir / \"fgr_starfit\"\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": domain_dir,\n",
    "    \"budget_type\": \"error\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "    \"netcdf_output_var_names\": [\n",
    "        \"node_outflows\",\n",
    "        \"node_upstream_inflows\",\n",
    "        \"node_storages\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb9546-c026-4aa8-b9ea-9d37d7ece0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhm_processes = [\n",
    "    pws.PRMSSolarGeometry,\n",
    "    pws.PRMSAtmosphere,\n",
    "    pws.PRMSCanopy,\n",
    "    pws.PRMSSnow,\n",
    "    pws.PRMSRunoff,\n",
    "    pws.PRMSSoilzone,\n",
    "    pws.PRMSGroundwater,  # stop here, we'll add PRMSChannel as part of FlowGraph later\n",
    "]\n",
    "\n",
    "model_dict = {\n",
    "    \"control\": control,\n",
    "    \"dis_both\": dis_hru,\n",
    "    \"dis_hru\": dis_both,\n",
    "    \"model_order\": [],\n",
    "}\n",
    "\n",
    "# As in notebook 01\n",
    "for proc in nhm_processes:\n",
    "    proc_name = proc.__name__\n",
    "    proc_rename = \"prms_\" + proc_name[4:].lower()\n",
    "    model_dict[\"model_order\"] += [proc_rename]\n",
    "    model_dict[proc_rename] = {}\n",
    "    proc_dict = model_dict[proc_rename]\n",
    "    proc_dict[\"class\"] = proc\n",
    "    proc_param_file = domain_dir / f\"parameters_{proc_name}.nc\"\n",
    "    proc_dict[\"parameters\"] = pws.Parameters.from_netcdf(proc_param_file)\n",
    "    if proc_rename == \"prms_channel\":\n",
    "        proc_dict[\"dis\"] = \"dis_both\"\n",
    "    else:\n",
    "        proc_dict[\"dis\"] = \"dis_hru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b170049-ec6b-4a6d-b183-98effa92d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what did that give us?\n",
    "pprint(model_dict, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f229c613-56fe-49c0-b211-f0f047eddc57",
   "metadata": {},
   "source": [
    "Now we have a model dictionary describing everything above the `PRMSChannel` (Musking-Mann). We have a very nice helper function, `prms_channel_flow_graph_to_model_dict`, we can use to add a `FlowGraph` to this model. The function takes the existing `model_dict`, the `PRMSChannel` information, plus additional user-supplied information, to construct a `FlowGraph` with a new `StarfitFlowNode` inserted in the `PRMSChannel` at the location above nhm segment 44426 (and below 44434 and 44435) to represent Big Sandy. This `FlowGraph` instance is added to the `model_dict` by name \"prms_channel_flow_graph\". \n",
    "\n",
    "The function will also add an `InflowExchange` instance to the `model_dict` named \"inflow_exchange\" which will manage getting the fluxes from PRMS to the FlowGraph. Zero lateral flows are supplied to the StarfitNode for Big Sandy in this case (though we could do otherwise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db25a89a-7a37-405e-ad09-1bfe682cabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = pws.prms_channel_flow_graph_to_model_dict(\n",
    "    model_dict=model_dict,\n",
    "    prms_channel_dis=dis_both,\n",
    "    prms_channel_dis_name=\"dis_both\",\n",
    "    prms_channel_params=params_channel,\n",
    "    new_nodes_maker_dict={\n",
    "        \"starfit\": pws.hydrology.starfit.StarfitFlowNodeMaker(\n",
    "            None,\n",
    "            sf_params,\n",
    "            budget_type=\"error\",\n",
    "            compute_daily=True,\n",
    "        )\n",
    "    },\n",
    "    new_nodes_maker_names=[\"starfit\"],\n",
    "    new_nodes_maker_indices=[0],\n",
    "    new_nodes_flow_to_nhm_seg=[44426],\n",
    "    graph_budget_type=\"warn\",  # move to error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2e182-0475-42cf-be92-2d36154cad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"inflow_exchange\" and \"prms_channel_flow_graph\" have been added to the model\n",
    "pprint(model_dict, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece847a1-c229-4813-9dee-eb3be5d1cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not run_dir.exists():\n",
    "    run_dir.mkdir()\n",
    "    model = pws.Model(model_dict)\n",
    "    model.run()\n",
    "    model.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e0ec9-340c-4668-b483-9df90f8f5936",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.processes[\"prms_channel_flow_graph\"].budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc97a64-807c-4fa3-a3a3-d4d404fd25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_44426 = np.where(params.parameters[\"nhm_seg\"] == 44426)[0]\n",
    "outflow_nodes = xr.open_dataarray(run_dir / \"node_outflows.nc\")[\n",
    "    :, wh_44426\n",
    "].drop_vars(\"node_coord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af336c0-e846-4fd9-a2d0-6728c4c42d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([outflow, outflow_nodes]).rename(\n",
    "    {\"seg_outflow\": \"NHM\", \"node_outflows\": \"STARFIT\"}\n",
    ").hvplot(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    ylabel=\"streamflow (cfs)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514e2590-a439-4ee5-90d2-625fa06f9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_nodes = xr.open_dataarray(run_dir / \"node_storages.nc\")[\n",
    "    :, -1\n",
    "].drop_vars(\"node_coord\")\n",
    "storage_nodes.hvplot(width=plot_width, height=plot_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31416c-f0ed-4adc-81bc-8e968f927b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([outflow, outflow_nodes, storage_nodes]).rename(\n",
    "    {\n",
    "        \"seg_outflow\": \"NHM\",\n",
    "        \"node_outflows\": \"Big Sandy Outflow\",\n",
    "        \"node_storages\": \"Big Sandy Storage\",\n",
    "    }\n",
    ").hvplot(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    ylabel=\"streamflow (cfs)\\nstorage (million cubic feet)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14432433-2385-4c21-992a-a05fc9524f11",
   "metadata": {},
   "source": [
    "## FlowGraph as a post-process: Drive FlowGraph with STARFIT representation of Big Sandy and Pass-Through using NHM output files\n",
    "Above we ran the full NHM with a `StarfitNode` at Big Sandy. But pywatershed is flexible and in the NHM configuration no two process representations are two-way coupled. See [figure in the extended release notes](https://ec-usgs.github.io/pywatershed/assets/img/pywatershed_NHM_model_graph.png). (Note that some PRMS configurations in pywatershed can be two-way coupled between Runoff and Soilzone and/or Canopy and Snow.) In this case, the `PRMSChannel` is one-way coupled (forced) buy the rest of the model. So we could use the output of the first, NHM run above without any reservoir representation and use its outupts to drive just the `FlowGraph` in the run above. We might call running `FlowGraph` in this way a \"post-process\". If one were running the no-reservoir model and looking at hypotheses of what FlowGraphs give better flow representations, this is the method you'd want to follow.\n",
    "\n",
    "So for this case we have a different helper function, `prms_channel_flow_graph_postprocess`, to which we supply most of the same information about the `FlowGraph`. However, we tell it about where it can find inputs from file rather than about an existing `model_dict` (as above).\n",
    "\n",
    "For additional extra fun and illustration, we'll not only add the `StarfitNode` for Big Sandy, we'll demonstrate that we can add additional nodes to the `FlowGraph` by putting a random `PassThroughNode` elsewhere on the domain. This node has no effect on the flows by design, but adding it here shows how additional nodes can easily be added to a `FlowGraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aaced3-9191-4acb-9043-24bcb2623e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pws.Control.load_prms(control_file, warn_unused_options=False)\n",
    "control.edit_n_time_steps(ndays_run)\n",
    "run_dir = nb_output_dir / \"fgr_starfit_post\"\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": domain_dir,\n",
    "    \"budget_type\": \"error\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "    \"netcdf_output_var_names\": [\n",
    "        \"node_outflows\",\n",
    "        \"node_upstream_inflows\",\n",
    "        \"node_storages\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "params_file_channel = domain_dir / \"parameters_PRMSChannel.nc\"\n",
    "params_channel = pws.parameters.PrmsParameters.from_netcdf(params_file_channel)\n",
    "\n",
    "if \"dis_hru\" in locals().keys():\n",
    "    del dis_hru\n",
    "\n",
    "dis_both_file = domain_dir / \"parameters_dis_both.nc\"\n",
    "dis_both = pws.Parameters.from_netcdf(dis_both_file, encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c52566-9032-49ed-8012-382c9f5cd5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfp_ds = sf_params.to_xr_ds().copy()\n",
    "cap_mult = 1.5\n",
    "sfp_ds[\"GRanD_CAP_MCM\"] *= cap_mult\n",
    "sf_params_new = pws.Parameters.from_ds(sfp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c8589-f15d-4174-b2c8-ffd0b7214b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = nb_output_dir / \"fgr_nhm\"  # use the output of the NHM run\n",
    "\n",
    "flow_graph = pws.prms_channel_flow_graph_postprocess(\n",
    "    control=control,\n",
    "    input_dir=input_dir,\n",
    "    prms_channel_dis=dis_both,\n",
    "    prms_channel_params=params_channel,\n",
    "    new_nodes_maker_dict={\n",
    "        \"starfit\": pws.hydrology.starfit.StarfitFlowNodeMaker(\n",
    "            None,\n",
    "            sf_params_new,\n",
    "            compute_daily=False,\n",
    "            budget_type=\"error\",\n",
    "        ),\n",
    "        \"pass_through\": pws.hydrology.pass_through_node.PassThroughNodeMaker(),\n",
    "    },\n",
    "    new_nodes_maker_names=[\"starfit\", \"pass_through\"],\n",
    "    new_nodes_maker_indices=[0, 0],  # relative to the indvidual NodeMakers\n",
    "    new_nodes_flow_to_nhm_seg=[\n",
    "        44426,\n",
    "        44435,\n",
    "    ],  # the second is a pass through above the first\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5619ab-f399-4303-a6f5-4e656971424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not run_dir.exists():\n",
    "    run_dir.mkdir()\n",
    "    flow_graph.initialize_netcdf()\n",
    "    for istep in tqdm(range(control.n_times)):\n",
    "        control.advance()\n",
    "        flow_graph.advance()\n",
    "        flow_graph.calculate(1.0)\n",
    "        flow_graph.output()\n",
    "\n",
    "    flow_graph.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c3100-3db4-489e-8d29-b755b0807cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_44426 = np.where(params.parameters[\"nhm_seg\"] == 44426)[0]\n",
    "outflow_nodes_post = (\n",
    "    xr.open_dataarray(run_dir / \"node_outflows.nc\")[:, wh_44426]\n",
    "    .drop_vars(\"node_coord\")\n",
    "    .rename(\"node_outflows_post\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9e92e-1e96-478c-a381-d5b2fd0d45db",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge(\n",
    "    [\n",
    "        outflow,\n",
    "        outflow_nodes,\n",
    "        outflow_nodes_post,\n",
    "    ]\n",
    ").rename(\n",
    "    {\n",
    "        \"seg_outflow\": \"NHM\",\n",
    "        \"node_outflows\": \"STARFIT\",\n",
    "        \"node_outflows_post\": f\"STARFIT CAP*{cap_mult}\",\n",
    "    }\n",
    ").hvplot(width=plot_width, height=plot_height, ylabel=\"streamflow (cfs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c762a-77e4-44d1-a75b-560ea9f6ceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_nodes_post = (\n",
    "    xr.open_dataarray(run_dir / \"node_storages.nc\")[\n",
    "        :, -2\n",
    "    ]  # pass through is the last node this time\n",
    "    .drop_vars(\"node_coord\")\n",
    "    .rename(\"node_storages_post\")\n",
    ")\n",
    "xr.merge(\n",
    "    [\n",
    "        storage_nodes,\n",
    "        storage_nodes_post,\n",
    "    ]\n",
    ").hvplot(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    ylabel=\"storage (million cubic feet)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38758377-ee47-4c77-8bb7-721e7581b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge(\n",
    "    [\n",
    "        outflow,\n",
    "        outflow_nodes,\n",
    "        storage_nodes,\n",
    "        outflow_nodes_post,\n",
    "        storage_nodes_post,\n",
    "    ]\n",
    ").rename(\n",
    "    {\n",
    "        \"seg_outflow\": \"NHM\",\n",
    "        \"node_outflows\": \"Big Sandy Outflow\",\n",
    "        \"node_storages\": \"Big Sandy Storage\",\n",
    "        \"node_outflows_post\": f\"Big Sandy Outflow CAP*{cap_mult}\",\n",
    "        \"node_storages_post\": f\"Big Sandy Storage CAP*{cap_mult}\",\n",
    "    }\n",
    ").hvplot(\n",
    "    width=plot_width,\n",
    "    height=plot_height,\n",
    "    ylabel=\"streamflow (cfs)\\nstorage (million cubic feet)\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
