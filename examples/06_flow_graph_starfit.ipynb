{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66cf7f2b-ca2e-40b0-81e9-6cf8bfd0e2eb",
   "metadata": {},
   "source": [
    "# FlowGraph with STARFit Reservoir: Big Sandy Reservoir\n",
    "1. Plot the plot, show where the reservoir should be\n",
    "2. Run the FGR simulation, look at flows out of where reservoir should be\n",
    "3. Insert the STARFit reservoir, compare flows.\n",
    "\n",
    "? Where will the FGR data reside? as release assets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cab067-be80-4743-b09a-410c215abfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import pathlib as pl\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from shutil import rmtree\n",
    "\n",
    "import jupyter_black\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import xarray as xr\n",
    "\n",
    "import hvplot.xarray  # noqa, after xr\n",
    "\n",
    "import pywatershed as pws\n",
    "from pywatershed.plot import DomainPlot\n",
    "from pywatershed.constants import __pywatershed_root__ as repo_root\n",
    "from pywatershed.constants import zero\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac724e3-5d9c-4e8e-9334-2f7f0be643b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_output_dir = pl.Path(\"./06_flow_graph_starfit\")\n",
    "if not nb_output_dir.exists():\n",
    "    nb_output_dir.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d5271-3976-430b-a754-b7a72e336704",
   "metadata": {},
   "source": [
    "## Big Sandy Reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2039fc5-dcb0-42fa-a5da-e9a9b9dd9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_data_dir = pl.Path(\"/Users/jmccreight/usgs/data/starfit_datasets/\")\n",
    "grand_file = sf_data_dir / \"GRanD_Version_1_3/GRanD_reservoirs_v1_3.shp\"\n",
    "istarf_file = sf_data_dir / \"ISTARF-CONUS.csv\"\n",
    "sf_params = pws.parameters.StarfitParameters.from_istarf_conus_grand(\n",
    "    grand_file=grand_file, istarf_file=istarf_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3dc6c5-3e67-461e-a7e6-2fd7617c2b03",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "grand_names = sf_params.parameters[\"GRanD_NAME\"].tolist()\n",
    "big_sandy_index = [\n",
    "    ii for ii, nn in enumerate(grand_names) if \"big sandy\" in str(nn).lower()\n",
    "][0]\n",
    "big_sandy_grand_id = sf_params.parameters[\"grand_id\"][big_sandy_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30c6e7-f71d-45c8-aa47-de0857e0e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a parameter set with just the big sandy dike\n",
    "sf_params = pws.parameters.StarfitParameters.from_istarf_conus_grand(\n",
    "    grand_file=grand_file, istarf_file=istarf_file, grand_ids=[big_sandy_index]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3878e-0308-413f-a1d1-36a8f64956d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_lat = sf_params.parameters[\"LAT_DD\"]\n",
    "start_lon = sf_params.parameters[\"LONG_DD\"]\n",
    "# unfortunately the above are for a different reservoir,\n",
    "# TODO: is the polygon correct?\n",
    "# the coords are easy to get on google maps\n",
    "start_lat = 42.25547378652696\n",
    "start_lon = -109.43063080023737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10004a14-785a-43f4-abc6-5102156d219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dir = pl.Path(\"/Users/jmccreight/usgs/data/pynhm/fgr\")\n",
    "domain_gis_dir = domain_dir / \"GIS\"\n",
    "\n",
    "control_file = domain_dir / \"nhm.control\"\n",
    "\n",
    "shp_file_hru = domain_gis_dir / \"model_nhru.shp\"\n",
    "shp_file_seg = domain_gis_dir / \"model_nsegment.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19533c6d-35b4-4017-9d03-a8992ca3f876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add GRanD shp file? or add to the object afterwards? option to get polygons\n",
    "# for sf_params above? but how to show connectivity?\n",
    "DomainPlot(\n",
    "    hru_shp_file=shp_file_hru,\n",
    "    segment_shp_file=shp_file_seg,\n",
    "    start_lat=start_lat,\n",
    "    start_lon=start_lon,\n",
    "    start_zoom=13,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ccde5-0a85-491e-911c-4045aa68aa12",
   "metadata": {},
   "source": [
    "From the above, including mousing over the segments, we can see the reservoir should be inserted above nhm_seg 44426 and below nhm_segs 44434 and 44435. \n",
    "\n",
    "## Flaming Gorge Domain run with NHM and NO RESERVOIR\n",
    "Let's look at the flows on segment 44426 with no reservoir present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b64dd07-cc07-4175-9f49-dffd532f7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pws.Control.load_prms(control_file, warn_unused_options=False)\n",
    "control.edit_n_time_steps(365 * 2)\n",
    "parameter_file = domain_dir / control.options[\"parameter_file\"]\n",
    "params = pws.parameters.PrmsParameters.load(parameter_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba984f-3402-416d-8800-0bee97158219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run just once\n",
    "# cbh_nc_dir = domain_dir\n",
    "# cbh_files = [\n",
    "#     domain_dir / \"prcp.cbh\",\n",
    "#     domain_dir / \"tmax.cbh\",\n",
    "#     domain_dir / \"tmin.cbh\",\n",
    "# ]\n",
    "\n",
    "# params = pws.parameters.PrmsParameters.load(domain_dir / \"myparam.param\")\n",
    "\n",
    "# for cbh_file in cbh_files:\n",
    "#     out_file = cbh_nc_dir / cbh_file.with_suffix(\".nc\").name\n",
    "#     pws.utils.cbh_file_to_netcdf(cbh_file, params, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288d4c9-a1f0-423f-b580-e43230651d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhm_processes = [\n",
    "    pws.PRMSSolarGeometry,\n",
    "    pws.PRMSAtmosphere,\n",
    "    pws.PRMSCanopy,\n",
    "    pws.PRMSSnow,\n",
    "    pws.PRMSRunoff,\n",
    "    pws.PRMSSoilzone,\n",
    "    pws.PRMSGroundwater,\n",
    "    pws.PRMSChannel,\n",
    "]\n",
    "\n",
    "# we'll use the to-channel fluxes later when running FlowGraph as a post-process\n",
    "control.options[\"netcdf_output_var_names\"] = [\n",
    "    \"seg_outflow\",\n",
    "    \"sroff_vol\",\n",
    "    \"ssres_flow_vol\",\n",
    "    \"gwres_flow_vol\",\n",
    "]\n",
    "run_dir = nb_output_dir / \"fgr_nhm\"\n",
    "\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": domain_dir,\n",
    "    \"budget_type\": \"error\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e96b9ba-1253-4a41-abfb-3444de3b37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_dir.exists():\n",
    "    # must delete the run dir to re-run\n",
    "    run_dir.mkdir()\n",
    "    nhm = pws.Model(\n",
    "        nhm_processes,\n",
    "        control=control,\n",
    "        parameters=params,\n",
    "    )\n",
    "    nhm.run(finalize=True)\n",
    "    nhm.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfb7bc-5ebe-4fb8-a4f6-91a8370f3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow = xr.open_dataarray(run_dir / \"seg_outflow.nc\").sel(nhm_seg=44426)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec64846-76af-4934-a304-f40f33b0cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07caf286-e581-4cbd-83ad-e0b960e56911",
   "metadata": {},
   "source": [
    "## FlowGraph in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328c9fd-8afd-4bd5-8326-ed093d3610d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_file_channel = domain_dir / \"parameters_PRMSChannel.nc\"\n",
    "params_channel = pws.parameters.PrmsParameters.from_netcdf(params_file_channel)\n",
    "\n",
    "dis_file = domain_dir / \"parameters_dis_hru.nc\"\n",
    "dis_hru = pws.Parameters.from_netcdf(dis_file, encoding=False)\n",
    "\n",
    "dis_both_file = domain_dir / \"parameters_dis_both.nc\"\n",
    "dis_both = pws.Parameters.from_netcdf(dis_both_file, encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d62fe-2742-48df-ae87-21ba419dd1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pws.Control.load_prms(control_file, warn_unused_options=False)\n",
    "control.edit_n_time_steps(365 * 2)\n",
    "run_dir = nb_output_dir / \"fgr_starfit\"\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": domain_dir,\n",
    "    \"budget_type\": \"error\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "    \"netcdf_output_var_names\": [\"node_outflows\", \"node_upstream_inflows\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb9546-c026-4aa8-b9ea-9d37d7ece0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhm_processes = [\n",
    "    pws.PRMSSolarGeometry,\n",
    "    pws.PRMSAtmosphere,\n",
    "    pws.PRMSCanopy,\n",
    "    pws.PRMSSnow,\n",
    "    pws.PRMSRunoff,\n",
    "    pws.PRMSSoilzone,\n",
    "    pws.PRMSGroundwater,\n",
    "]\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "for proc in nhm_processes:\n",
    "    # this is the class name\n",
    "    proc_name = proc.__name__\n",
    "    # the processes can have arbitrary names in the model_dict and\n",
    "    # an instance should not have capitalized name anyway (according to\n",
    "    # python convention), so rename from the class name\n",
    "    proc_rename = \"prms_\" + proc_name[4:].lower()\n",
    "    # each process has a dictionary of information\n",
    "    model_dict[proc_rename] = {}\n",
    "    # alias to shorten lines below\n",
    "    proc_dict = model_dict[proc_rename]\n",
    "    # required key \"class\" specifys the class\n",
    "    proc_dict[\"class\"] = proc\n",
    "    # the \"parameters\" key provides an instance of Parameters\n",
    "    proc_param_file = domain_dir / f\"parameters_{proc_name}.nc\"\n",
    "    proc_dict[\"parameters\"] = pws.Parameters.from_netcdf(proc_param_file)\n",
    "    # the \"dis\" key provides the name of the discretizations\n",
    "    # which we'll supply shortly to the model dictionary\n",
    "    if proc_rename == \"prms_channel\":\n",
    "        proc_dict[\"dis\"] = \"dis_both\"\n",
    "    else:\n",
    "        proc_dict[\"dis\"] = \"dis_hru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b170049-ec6b-4a6d-b183-98effa92d6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(model_dict, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11da428-a08c-48e1-8c05-c893bedb7dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this graph will have no-inflow to non-prms_channel nodes. could those be added later?\n",
    "def prms_channel_flow_graph_preprocess(\n",
    "    prms_channel_params,\n",
    "    prms_channel_dis,\n",
    "    prms_channel_dis_name,\n",
    "    new_nodes_maker_dict,\n",
    "    new_nodes_maker_names,\n",
    "    new_nodes_maker_indices,\n",
    "    new_nodes_flow_to_nhm_seg,\n",
    "    graph_budget_type=\"error\",\n",
    "):\n",
    "\n",
    "    prms_channel_flow_makers = [\n",
    "        type(vv)\n",
    "        for vv in new_nodes_maker_dict.values()\n",
    "        if isinstance(vv, pws.PRMSChannelFlowNodeMaker)\n",
    "    ]\n",
    "    assert len(prms_channel_flow_makers) == 0\n",
    "\n",
    "    assert len(new_nodes_maker_names) == len(new_nodes_maker_indices), \"nono\"\n",
    "    assert len(new_nodes_maker_names) == len(new_nodes_flow_to_nhm_seg), \"NONO\"\n",
    "    # JLM: I think this is the only condition to check with new_nodes_flow_to_nhm_seg\n",
    "    assert len(new_nodes_flow_to_nhm_seg) == len(\n",
    "        np.unique(new_nodes_flow_to_nhm_seg)\n",
    "    ), \"OHNO\"\n",
    "\n",
    "    nseg = prms_channel_params.dims[\"nsegment\"]\n",
    "    nnodes = nseg + len(new_nodes_maker_names)\n",
    "\n",
    "    node_maker_name = [\"prms_channel\"] * nseg + new_nodes_maker_names\n",
    "    node_maker_index = np.array(\n",
    "        np.arange(nseg).tolist() + new_nodes_maker_indices\n",
    "    )\n",
    "\n",
    "    to_graph_index = np.zeros(nnodes, dtype=np.int64)\n",
    "    dis_params = prms_channel_dis.parameters\n",
    "    tosegment = dis_params[\"tosegment\"] - 1  # fortan to python indexing\n",
    "    to_graph_index[0:nseg] = tosegment\n",
    "\n",
    "    for ii, nhm_seg in enumerate(new_nodes_flow_to_nhm_seg):\n",
    "        wh_intervene_above_nhm = np.where(dis_params[\"nhm_seg\"] == nhm_seg)\n",
    "        wh_intervene_below_nhm = np.where(\n",
    "            tosegment == wh_intervene_above_nhm[0][0]\n",
    "        )\n",
    "        # have to map to the graph from an index found in prms_channel\n",
    "        wh_intervene_above_graph = np.where(\n",
    "            (np.array(node_maker_name) == \"prms_channel\")\n",
    "            & (node_maker_index == wh_intervene_above_nhm[0][0])\n",
    "        )\n",
    "        wh_intervene_below_graph = np.where(\n",
    "            (np.array(node_maker_name) == \"prms_channel\")\n",
    "            & np.isin(node_maker_index, wh_intervene_below_nhm)\n",
    "        )\n",
    "\n",
    "        to_graph_index[nseg + ii] = wh_intervene_above_graph[0][0]\n",
    "        to_graph_index[wh_intervene_below_graph] = nseg + ii\n",
    "\n",
    "    params_flow_graph = pws.Parameters(\n",
    "        dims={\n",
    "            \"nnodes\": nnodes,\n",
    "        },\n",
    "        coords={\n",
    "            \"node_coord\": np.arange(nnodes),\n",
    "        },\n",
    "        data_vars={\n",
    "            \"node_maker_name\": node_maker_name,\n",
    "            \"node_maker_index\": node_maker_index,\n",
    "            \"to_graph_index\": to_graph_index,\n",
    "        },\n",
    "        metadata={\n",
    "            \"node_coord\": {\"dims\": [\"nnodes\"]},\n",
    "            \"node_maker_name\": {\"dims\": [\"nnodes\"]},\n",
    "            \"node_maker_index\": {\"dims\": [\"nnodes\"]},\n",
    "            \"to_graph_index\": {\"dims\": [\"nnodes\"]},\n",
    "        },\n",
    "        validate=True,\n",
    "    )\n",
    "\n",
    "    # make available at top level __init__\n",
    "    node_maker_dict = {\n",
    "        \"prms_channel\": pws.PRMSChannelFlowNodeMaker(dis_both, params_channel),\n",
    "    } | new_nodes_maker_dict\n",
    "\n",
    "    def exchange_calculation(self) -> None:\n",
    "        _hru_segment = self.hru_segment - 1\n",
    "        s_per_time = self.control.time_step_seconds\n",
    "        self._inputs_sum = (\n",
    "            sum([vv.current for vv in self._input_variables_dict.values()])\n",
    "            / s_per_time\n",
    "        )\n",
    "\n",
    "        # This zero in the last index means zero inflows to the pass through\n",
    "        # node\n",
    "        self.inflows[:] = zero\n",
    "        # sinks is an HRU variable, its accounting in budget is fine because\n",
    "        # global collapses it to a scalar before summing over variables\n",
    "        self.sinks[:] = zero\n",
    "\n",
    "        for ihru in range(self.nhru):\n",
    "            iseg = _hru_segment[ihru]\n",
    "            if iseg < 0:\n",
    "                self.sinks[ihru] += self._inputs_sum[ihru]\n",
    "            else:\n",
    "                self.inflows[iseg] += self._inputs_sum[ihru]\n",
    "\n",
    "        self.inflows_vol[:] = self.inflows * s_per_time\n",
    "        self.sinks_vol[:] = self.sinks * s_per_time\n",
    "\n",
    "    Exchange = pws.base.flow_graph.inflow_exchange_factory(\n",
    "        dimension_names=(\"nhru\", \"nnodes\"),\n",
    "        parameter_names=(\"hru_segment\", \"node_coord\"),\n",
    "        input_names=pws.PRMSChannel.get_inputs(),\n",
    "        init_values={\n",
    "            \"inflows\": np.nan,\n",
    "            \"inflows_vol\": np.nan,\n",
    "            \"sinks\": np.nan,\n",
    "            \"sinks_vol\": np.nan,\n",
    "        },\n",
    "        mass_budget_terms={\n",
    "            \"inputs\": [\n",
    "                \"sroff_vol\",\n",
    "                \"ssres_flow_vol\",\n",
    "                \"gwres_flow_vol\",\n",
    "            ],\n",
    "            \"outputs\": [\"inflows_vol\", \"sinks_vol\"],\n",
    "            \"storage_changes\": [],\n",
    "        },\n",
    "        calculation=exchange_calculation,\n",
    "    )  # get the budget type into the exchange too: exchange_budget_type\n",
    "\n",
    "    # Exchange parameters\n",
    "    # TODO: this is funky, can we make this more elegant?\n",
    "    params_ds = params_channel.to_xr_ds().copy()\n",
    "    params_ds[\"node_coord\"] = xr.Variable(\n",
    "        dims=\"nnodes\",\n",
    "        data=np.arange(nnodes),\n",
    "    )\n",
    "    params_ds = params_ds.set_coords(\"node_coord\")\n",
    "    params_exchange = pws.Parameters.from_ds(params_ds)\n",
    "\n",
    "    return {\n",
    "        \"inflow_exchange\": {\n",
    "            \"class\": Exchange,\n",
    "            \"parameters\": params_exchange,\n",
    "            \"dis\": prms_channel_dis_name,\n",
    "        },\n",
    "        \"prms_channel_flow_graph\": {\n",
    "            \"class\": pws.FlowGraph,\n",
    "            \"node_maker_dict\": node_maker_dict,\n",
    "            \"parameters\": params_flow_graph,\n",
    "            \"dis\": None,\n",
    "            \"budget_type\": graph_budget_type,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db25a89a-7a37-405e-ad09-1bfe682cabd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_maker_dict = {\n",
    "    \"pass_throughs\": pws.hydrology.pass_through_node.PassThroughNodeMaker()\n",
    "}  # to make STARFIT\n",
    "\n",
    "# could pass the model_dict and return the model_dict?\n",
    "# do it for 2+ reservoirs/pass throughs\n",
    "graph_dict = prms_channel_flow_graph_preprocess(\n",
    "    params_channel,\n",
    "    dis_both,\n",
    "    \"dis_both\",\n",
    "    {\"pass_through\": pws.hydrology.pass_through_node.PassThroughNodeMaker()},\n",
    "    [\"pass_through\"] * 2,\n",
    "    [0, 1],\n",
    "    [44426, 44418],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39803260-f8a3-48c8-a07d-11314a6bcdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nhm_processes_names = [\n",
    "    (\"prms_\" + pp.__name__.lower()[4:]) for pp in nhm_processes\n",
    "]\n",
    "model_order = nhm_processes_names + list(graph_dict.keys())\n",
    "\n",
    "model_dict = (\n",
    "    model_dict\n",
    "    | {\n",
    "        \"control\": control,\n",
    "        \"dis_both\": dis_hru,\n",
    "        \"dis_hru\": dis_both,\n",
    "        \"model_order\": model_order,\n",
    "    }\n",
    "    | graph_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece847a1-c229-4813-9dee-eb3be5d1cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_dir.exists():\n",
    "    run_dir.mkdir()\n",
    "    model = pws.Model(model_dict)\n",
    "    model.run()\n",
    "    model.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc97a64-807c-4fa3-a3a3-d4d404fd25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_44426 = np.where(params.parameters[\"nhm_seg\"] == 44426)[0]\n",
    "outflow_nodes = xr.open_dataarray(run_dir / \"node_outflows.nc\")[\n",
    "    :, wh_44426\n",
    "].drop_vars(\"node_coord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c554544-1f3c-42af-9430-32cbed04f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (abs(outflow_nodes - outflow) < 1e-9).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af336c0-e846-4fd9-a2d0-6728c4c42d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([outflow, outflow_nodes]).hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14432433-2385-4c21-992a-a05fc9524f11",
   "metadata": {},
   "source": [
    "## FlowGraph as a post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aaced3-9191-4acb-9043-24bcb2623e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = pws.Control.load_prms(control_file, warn_unused_options=False)\n",
    "control.edit_n_time_steps(365 * 2)\n",
    "run_dir = nb_output_dir / \"fgr_starfit_post\"\n",
    "control.options = control.options | {\n",
    "    \"input_dir\": domain_dir,\n",
    "    \"budget_type\": \"error\",\n",
    "    \"calc_method\": \"numba\",\n",
    "    \"netcdf_output_dir\": run_dir,\n",
    "    \"netcdf_output_var_names\": [\"node_outflows\", \"node_upstream_inflows\"],\n",
    "}\n",
    "\n",
    "params_file_channel = domain_dir / \"parameters_PRMSChannel.nc\"\n",
    "params_channel = pws.parameters.PrmsParameters.from_netcdf(params_file_channel)\n",
    "\n",
    "# dis_file = domain_dir / \"parameters_dis_hru.nc\"\n",
    "# dis_hru = pws.Parameters.from_netcdf(dis_file, encoding=False)\n",
    "if \"dis_hru\" in locals().keys():\n",
    "    del dis_hru\n",
    "\n",
    "dis_both_file = domain_dir / \"parameters_dis_both.nc\"\n",
    "dis_both = pws.Parameters.from_netcdf(dis_both_file, encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213677e-faa9-454a-aa67-14c40c3be49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prms_channel_flow_graph_postprocess(\n",
    "    input_dir,\n",
    "    prms_channel_params,\n",
    "    prms_channel_dis,\n",
    "    new_nodes_maker_dict,\n",
    "    new_nodes_maker_names,\n",
    "    new_nodes_maker_indices,\n",
    "    new_nodes_flow_to_nhm_seg,\n",
    "    graph_budget_type=\"error\",\n",
    "):\n",
    "\n",
    "    prms_channel_flow_makers = [\n",
    "        type(vv)\n",
    "        for vv in new_nodes_maker_dict.values()\n",
    "        if isinstance(vv, pws.PRMSChannelFlowNodeMaker)\n",
    "    ]\n",
    "    assert len(prms_channel_flow_makers) == 0\n",
    "\n",
    "    assert len(new_nodes_maker_names) == len(new_nodes_maker_indices), \"nono\"\n",
    "    assert len(new_nodes_maker_names) == len(new_nodes_flow_to_nhm_seg), \"NONO\"\n",
    "    # JLM: I think this is the only condition to check with new_nodes_flow_to_nhm_seg\n",
    "    assert len(new_nodes_flow_to_nhm_seg) == len(\n",
    "        np.unique(new_nodes_flow_to_nhm_seg)\n",
    "    ), \"OHNO\"\n",
    "\n",
    "    nseg = prms_channel_params.dims[\"nsegment\"]\n",
    "    nnodes = nseg + len(new_nodes_maker_names)\n",
    "\n",
    "    node_maker_name = [\"prms_channel\"] * nseg + new_nodes_maker_names\n",
    "    node_maker_index = np.array(\n",
    "        np.arange(nseg).tolist() + new_nodes_maker_indices\n",
    "    )\n",
    "\n",
    "    to_graph_index = np.zeros(nnodes, dtype=np.int64)\n",
    "    dis_params = prms_channel_dis.parameters\n",
    "    tosegment = dis_params[\"tosegment\"] - 1  # fortan to python indexing\n",
    "    to_graph_index[0:nseg] = tosegment\n",
    "\n",
    "    for ii, nhm_seg in enumerate(new_nodes_flow_to_nhm_seg):\n",
    "        wh_intervene_above_nhm = np.where(dis_params[\"nhm_seg\"] == nhm_seg)\n",
    "        wh_intervene_below_nhm = np.where(\n",
    "            tosegment == wh_intervene_above_nhm[0][0]\n",
    "        )\n",
    "        # have to map to the graph from an index found in prms_channel\n",
    "        wh_intervene_above_graph = np.where(\n",
    "            (np.array(node_maker_name) == \"prms_channel\")\n",
    "            & (node_maker_index == wh_intervene_above_nhm[0][0])\n",
    "        )\n",
    "        wh_intervene_below_graph = np.where(\n",
    "            (np.array(node_maker_name) == \"prms_channel\")\n",
    "            & np.isin(node_maker_index, wh_intervene_below_nhm)\n",
    "        )\n",
    "\n",
    "        to_graph_index[nseg + ii] = wh_intervene_above_graph[0][0]\n",
    "        to_graph_index[wh_intervene_below_graph] = nseg + ii\n",
    "\n",
    "    params_flow_graph = pws.Parameters(\n",
    "        dims={\n",
    "            \"nnodes\": nnodes,\n",
    "        },\n",
    "        coords={\n",
    "            \"node_coord\": np.arange(nnodes),\n",
    "        },\n",
    "        data_vars={\n",
    "            \"node_maker_name\": node_maker_name,\n",
    "            \"node_maker_index\": node_maker_index,\n",
    "            \"to_graph_index\": to_graph_index,\n",
    "        },\n",
    "        metadata={\n",
    "            \"node_coord\": {\"dims\": [\"nnodes\"]},\n",
    "            \"node_maker_name\": {\"dims\": [\"nnodes\"]},\n",
    "            \"node_maker_index\": {\"dims\": [\"nnodes\"]},\n",
    "            \"to_graph_index\": {\"dims\": [\"nnodes\"]},\n",
    "        },\n",
    "        validate=True,\n",
    "    )\n",
    "\n",
    "    # make available at top level __init__\n",
    "    node_maker_dict = {\n",
    "        \"prms_channel\": pws.PRMSChannelFlowNodeMaker(dis_both, params_channel),\n",
    "    } | new_nodes_maker_dict\n",
    "\n",
    "    # ---------XXXXXXXXXX----------\n",
    "    # combine PRMS lateral inflows to a single non-volumetric inflow\n",
    "    input_variables = {}\n",
    "    for key in pws.PRMSChannel.get_inputs():\n",
    "        nc_path = input_dir / f\"{key}.nc\"\n",
    "        input_variables[key] = pws.AdapterNetcdf(nc_path, key, control)\n",
    "\n",
    "    inflows_prms = pws.hydrology.prms_channel_flow_graph.HruSegmentFlowAdapter(\n",
    "        params_channel, **input_variables\n",
    "    )\n",
    "\n",
    "    class GraphInflowAdapter(pws.Adapter):\n",
    "        def __init__(\n",
    "            self,\n",
    "            prms_inflows: pws.Adapter,\n",
    "            variable: str = \"inflows\",\n",
    "        ):\n",
    "            self._variable = variable\n",
    "            self._prms_inflows = prms_inflows\n",
    "\n",
    "            self._nnodes = nnodes\n",
    "            self._nseg = nseg\n",
    "            self._current_value = np.zeros(self._nnodes) * pws.constants.nan\n",
    "            return\n",
    "\n",
    "        def advance(self) -> None:\n",
    "            self._prms_inflows.advance()\n",
    "            self._current_value[0:nseg] = self._prms_inflows.current\n",
    "            self._current_value[nseg:] = (\n",
    "                zero  # no inflow non-prms-channel nodes\n",
    "            )\n",
    "            return\n",
    "\n",
    "    inflows_graph = GraphInflowAdapter(inflows_prms)\n",
    "\n",
    "    flow_graph = pws.FlowGraph(\n",
    "        control=control,\n",
    "        discretization=dis_both,\n",
    "        parameters=params_flow_graph,\n",
    "        inflows=inflows_graph,\n",
    "        node_maker_dict=node_maker_dict,\n",
    "        budget_type=\"error\",\n",
    "    )\n",
    "    return flow_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c8589-f15d-4174-b2c8-ffd0b7214b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = nb_output_dir / \"fgr_nhm\"  # use the output of the NHM run\n",
    "flow_graph = prms_channel_flow_graph_postprocess(\n",
    "    input_dir,\n",
    "    params_channel,\n",
    "    dis_both,\n",
    "    {\"pass_through\": pws.hydrology.pass_through_node.PassThroughNodeMaker()},\n",
    "    [\"pass_through\"] * 2,\n",
    "    [0, 1],\n",
    "    [44426, 44418],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5619ab-f399-4303-a6f5-4e656971424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_dir.exists():\n",
    "    run_dir.mkdir()\n",
    "    flow_graph.initialize_netcdf()\n",
    "    for istep in tqdm(range(control.n_times)):\n",
    "        control.advance()\n",
    "        flow_graph.advance()\n",
    "        flow_graph.calculate(1.0)\n",
    "        flow_graph.output()\n",
    "\n",
    "    flow_graph.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52c3100-3db4-489e-8d29-b755b0807cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_44426 = np.where(params.parameters[\"nhm_seg\"] == 44426)[0]\n",
    "outflow_nodes_post = (\n",
    "    xr.open_dataarray(run_dir / \"node_outflows.nc\")[:, wh_44426]\n",
    "    .drop_vars(\"node_coord\")\n",
    "    .rename(\"node_outflows_post\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5208f2-f21c-4cac-ab58-21099b90b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (abs(outflow_nodes_post - outflow) < 1e-9).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4db0fb8-542e-4f57-86b3-2890c8a3d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.merge([outflow, outflow_nodes, outflow_nodes_post]).hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c762a-77e4-44d1-a75b-560ea9f6ceda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
